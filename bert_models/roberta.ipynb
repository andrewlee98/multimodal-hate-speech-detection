{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "import gc\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8500\n",
      "500\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# make image dataloader using flow_from_dataframe\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# load data to extract labels\n",
    "data_dir = '../facebook_challenge_data/'\n",
    "model_dir = 'models/'\n",
    "\n",
    "# load data and print sizes\n",
    "def get_dict(path):\n",
    "    jsonl_content = open(path, 'r').read()\n",
    "    data = [json.loads(jline) for jline in jsonl_content.split('\\n')]\n",
    "    return {datum['id'] : datum for datum in data}\n",
    "\n",
    "\n",
    "train_dict = get_dict(data_dir + 'train.jsonl')\n",
    "val_dict = get_dict(data_dir + 'dev.jsonl')\n",
    "test_dict = get_dict(data_dir + 'test.jsonl')\n",
    "\n",
    "print(len(train_dict))\n",
    "print(len(val_dict))\n",
    "print(len(test_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained roberta\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, TFRobertaModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "class ROBERTA(transformers.TFRobertaModel):\n",
    "\n",
    "    def __init__(self, config, *inputs, **kwargs):\n",
    "        super(ROBERTA, self).__init__(config, *inputs, **kwargs)\n",
    "        self.roberta.call = tf.function(self.roberta.call)\n",
    "        self.roberta.trainable = False # freeze pretrained roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained resnet\n",
    "# image_encoder = tf.keras.applications.ResNet50(include_top=False, \n",
    "#                                weights='imagenet', \n",
    "#                                input_shape=(299, 299, 3)\n",
    "# )\n",
    "\n",
    "# load inception bc of memory constraints\n",
    "image_encoder = tf.keras.applications.InceptionV3(include_top=False, \n",
    "                               weights='imagenet', \n",
    "                               input_shape=(299, 299, 3)\n",
    ")\n",
    "\n",
    "for layer in image_encoder.layers[:-1]: layer.trainable = False # freeze pretrained layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 70)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "roberta (ROBERTA)               ((None, 70, 768), (N 124645632   input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 1, 768)]     0           roberta[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "inception_v3 (Model)            (None, 8, 8, 2048)   21802784    input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze (TensorFlow [(None, 768)]        0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 131072)       0           inception_v3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          393728      tf_op_layer_Squeeze[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2048)         268437504   flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 2560)         0           dense[0][0]                      \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          1311232     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          131328      dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            257         dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 416,722,465\n",
      "Trainable params: 270,274,049\n",
      "Non-trainable params: 146,448,416\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# https://keras.io/examples/nlp/text_extraction_with_bert/\n",
    "# https://github.com/huggingface/transformers/issues/1350\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "max_len = 70\n",
    "\n",
    "# handle text\n",
    "input_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
    "roberta = ROBERTA.from_pretrained('roberta-base')\n",
    "roberta_encodings = roberta([input_ids])[0]\n",
    "text_embed = tf.squeeze(roberta_encodings[:, 0:1, :], axis=1) # Keep [CLS] token encoding\n",
    "text_embed = layers.Dense(512)(text_embed)\n",
    "\n",
    "\n",
    "# handle image\n",
    "input_img = Input((299, 299, 3))\n",
    "img_embed = image_encoder(input_img)\n",
    "img_embed = layers.Flatten()(img_embed)\n",
    "img_embed = layers.Dense(2048)(img_embed)\n",
    "\n",
    "# concat\n",
    "pred = layers.Concatenate()([text_embed, img_embed])\n",
    "pred = layers.Dense(512, activation='relu')(pred)\n",
    "pred = layers.Dense(256, activation='relu')(pred)\n",
    "pred = layers.Dense(1, activation='sigmoid')(pred)\n",
    "\n",
    "model = Model(\n",
    "    inputs=[input_ids, input_img],\n",
    "    outputs=pred,\n",
    ")\n",
    "\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "optimizer = tf.keras.optimizers.Adam(lr=1e-6)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint # for random cropping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "class FBMMDataGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, data_dict, tokenizer, pad_len, batch_size=32, dim=(299, 299), n_channels=3, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.data_dict = data_dict\n",
    "        self.batch_size = batch_size\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.pad_len = pad_len\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        # build labels list and id list\n",
    "        self.id_list = list(self.data_dict.keys())\n",
    "        self.labels = {ID: self.data_dict[ID]['label'] for ID in self.id_list}\n",
    "        self.img_list = {ID: self.data_dict[ID]['img'] for ID in self.id_list}\n",
    "            \n",
    "        # get text dictionary\n",
    "        self.text_dict = self.process_text(self.id_list)\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "        self.classes = [self.labels[self.id_list[i]] for i in self.indexes]\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.id_list) / self.batch_size)) + 1 # last batch is partial\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:index*self.batch_size + self.batch_size]\n",
    "        \n",
    "        \n",
    "        # Find list of IDs\n",
    "        id_list_temp = [self.id_list[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X_txt, X_img, y = self.__data_generation(id_list_temp)\n",
    "        \n",
    "        return (X_txt, X_img), y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.id_list))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, id_list_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X_img = np.empty((len(id_list_temp), *self.dim, self.n_channels))\n",
    "        X_txt = np.empty((len(id_list_temp), self.pad_len))\n",
    "        y = np.empty(len(id_list_temp), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(id_list_temp):\n",
    "            # Store sample\n",
    "            X_img[i,] = self.process_img(data_dir + self.img_list[ID])\n",
    "            X_txt[i,] = self.text_dict[ID]\n",
    "\n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X_txt.astype(int), X_img, y\n",
    "    \n",
    "    def process_img(self, path): # method for getting image\n",
    "        img = Image.open(path)\n",
    "        img.load()\n",
    "        img = img.resize(self.dim, Image.ANTIALIAS)\n",
    "        data = np.asarray(img, dtype='uint8')\n",
    "        im = self.augment(data)\n",
    "        \n",
    "        \n",
    "        if im.shape==(self.dim[0], self.dim[1]): im = np.stack((im,)*3, axis=-1) # handle grayscale\n",
    "        if im.shape == (*self.dim, 4): im = im[:,:,:3] # handle weird case\n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def augment(self, im): # random crop and random mirror\n",
    "        \n",
    "        # random crop\n",
    "        x_max, y_max = im.shape[0], im.shape[1]\n",
    "        x_start, y_start = randint(0, x_max - self.dim[0]), randint(0, y_max - self.dim[1])\n",
    "        im = im[x_start:x_start + self.dim[0], y_start:y_start + self.dim[1]]\n",
    "        \n",
    "        # random mirror\n",
    "        if randint(0,1): im = np.flip(im, axis=1)\n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def process_text(self, id_list):\n",
    "        \n",
    "        # matrix for texts\n",
    "        texts = [self.data_dict[ID]['text'] for ID in id_list]\n",
    "        sequences = [self.tokenizer.encode(text) for text in texts] # make this more efficient...\n",
    "        text_seqs = pad_sequences(sequences, maxlen=self.pad_len)\n",
    "        \n",
    "        id_to_seq = {ID: txt for (ID, txt) in zip(id_list, text_seqs)} # map id to text seq\n",
    "        \n",
    "        return id_to_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.tokenization_roberta.RobertaTokenizer'>\n",
      "[0, 3592, 127, 766, 16, 22401, 8, 939, 101, 7, 213, 7358, 2]\n",
      "[0, 3, 42891, 2]\n"
     ]
    }
   ],
   "source": [
    "# test tokenizer\n",
    "\n",
    "print(type(tokenizer))\n",
    "print(tokenizer.encode('hi my name is bob and i like to go swimming'))\n",
    "print(tokenizer.encode(['hi my name is bob and i like to go swimming', 'hello']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data generators\n",
    "\n",
    "# create data generators\n",
    "train_gen = FBMMDataGenerator(data_dict=train_dict,\n",
    "                          tokenizer=tokenizer,\n",
    "                          pad_len=max_len,\n",
    "                          batch_size=16,\n",
    "                          dim=(299, 299),\n",
    "                          n_channels=3,\n",
    "                          shuffle=True)\n",
    "\n",
    "val_gen = FBMMDataGenerator(data_dict=val_dict,\n",
    "                          tokenizer=tokenizer,\n",
    "                          pad_len=max_len,\n",
    "                          batch_size=16,\n",
    "                          dim=(299, 299),\n",
    "                          n_channels=3,\n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "531/532 [============================>.] - ETA: 1s - loss: 0.6715 - accuracy: 0.6185\n",
      "Epoch 00001: val_loss improved from inf to 7.78727, saving model to models/best_roberta.h5\n",
      "532/532 [==============================] - 875s 2s/step - loss: 0.6714 - accuracy: 0.6185 - val_loss: 7.7873 - val_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "531/532 [============================>.] - ETA: 1s - loss: 0.6362 - accuracy: 0.6396\n",
      "Epoch 00002: val_loss improved from 7.78727 to 7.68796, saving model to models/best_roberta.h5\n",
      "532/532 [==============================] - 793s 1s/step - loss: 0.6360 - accuracy: 0.6398 - val_loss: 7.6880 - val_accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "531/532 [============================>.] - ETA: 1s - loss: 0.6137 - accuracy: 0.6624\n",
      "Epoch 00003: val_loss did not improve from 7.68796\n",
      "532/532 [==============================] - 752s 1s/step - loss: 0.6140 - accuracy: 0.6622 - val_loss: 7.8029 - val_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "531/532 [============================>.] - ETA: 1s - loss: 0.5859 - accuracy: 0.6875\n",
      "Epoch 00004: val_loss improved from 7.68796 to 7.65470, saving model to models/best_roberta.h5\n",
      "532/532 [==============================] - 782s 1s/step - loss: 0.5860 - accuracy: 0.6873 - val_loss: 7.6547 - val_accuracy: 0.4980\n",
      "Epoch 5/5\n",
      "531/532 [============================>.] - ETA: 1s - loss: 0.5637 - accuracy: 0.7007\n",
      "Epoch 00005: val_loss improved from 7.65470 to 7.51147, saving model to models/best_roberta.h5\n",
      "532/532 [==============================] - 784s 1s/step - loss: 0.5638 - accuracy: 0.7007 - val_loss: 7.5115 - val_accuracy: 0.4980\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "mcp_save = ModelCheckpoint(model_dir + 'best_roberta.h5', \n",
    "                           save_weights_only=True, \n",
    "                           save_best_only=True, \n",
    "                           verbose=1,\n",
    "                           monitor='val_loss', \n",
    "                           mode='min')\n",
    "\n",
    "history = model.fit_generator(train_gen,\n",
    "                    validation_data=val_gen,\n",
    "                    shuffle=True,\n",
    "                    epochs=5,\n",
    "                    callbacks=[mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(model_dir + 'best_roberta.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val AUROC: 0.495888\n",
      "Val Accuracy: 0.498\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score\n",
    "import math\n",
    "\n",
    "y_val = val_gen.classes\n",
    "\n",
    "# get AUROC\n",
    "preds = model.predict_generator(val_gen)\n",
    "print('Val AUROC:', roc_auc_score(y_val, preds))\n",
    "\n",
    "# get loss and acc\n",
    "preds_bin = np.array(preds)\n",
    "preds_bin[preds>0.5] = 1\n",
    "preds_bin[preds<=0.5] = 0\n",
    "print('Val Accuracy:', accuracy_score(y_val, preds_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python36env",
   "language": "python",
   "name": "python36env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
