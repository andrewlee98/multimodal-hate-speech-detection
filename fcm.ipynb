{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import cv2\n",
    "import re\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make image dataloader using flow_from_dataframe\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# load data to extract labels\n",
    "data_dir = 'mmhs150k/'\n",
    "model_dir = 'models/'\n",
    "tweet_dict = json.load(open(data_dir + 'MMHS150K_GT.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 100)           7565100   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 150)               150600    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 150)               22650     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 7,738,501\n",
      "Trainable params: 173,401\n",
      "Non-trainable params: 7,565,100\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 8, 8, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              134218752 \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 156,546,849\n",
      "Trainable params: 134,744,065\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# load pretrained LSTM and CNN for text and images\n",
    "from keras.models import load_model\n",
    "\n",
    "lstm = load_model(model_dir + 'lstm.h5')\n",
    "cnn = load_model(model_dir + 'CNN.h5')\n",
    "\n",
    "print(lstm.summary())\n",
    "print(cnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 100)           7565100   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 150)               150600    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 150)               22650     \n",
      "=================================================================\n",
      "Total params: 7,738,350\n",
      "Trainable params: 173,250\n",
      "Non-trainable params: 7,565,100\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 8, 8, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              134218752 \n",
      "=================================================================\n",
      "Total params: 156,021,536\n",
      "Trainable params: 134,218,752\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create new models that are all but the last layer\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "text_net = Sequential()\n",
    "for layer in lstm.layers[:-1]: text_net.add(layer)\n",
    "print(text_net.summary())\n",
    "\n",
    "img_net = Sequential()\n",
    "for layer in cnn.layers[:-2]: img_net.add(layer)\n",
    "print(img_net.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_33 (InputLayer)           (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_34 (InputLayer)           (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_35 (InputLayer)           (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_8 (Sequential)       (None, 150)          7738350     input_33[0][0]                   \n",
      "                                                                 input_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sequential_9 (Sequential)       (None, 1024)         156021536   input_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1324)         0           sequential_8[1][0]               \n",
      "                                                                 sequential_8[2][0]               \n",
      "                                                                 sequential_9[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 2348)         3111100     concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1024)         2405376     dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 512)          524800      dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 1)            513         dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 169,801,675\n",
      "Trainable params: 140,433,791\n",
      "Non-trainable params: 29,367,884\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# build full FCM model using concatenation layer\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers import Dense, Input\n",
    "\n",
    "text_input = Input((text_net.layers[0].input_shape[-1],)) # get rid of None's in front\n",
    "img_text_input = Input((text_net.layers[0].input_shape[-1],))\n",
    "img_input = Input((img_net.layers[0].input_shape[1:])) # get rid of None in front\n",
    "\n",
    "text_embed = text_net(text_input)\n",
    "img_text_embed = text_net(img_text_input)\n",
    "img_embed = img_net(img_input)\n",
    "\n",
    "x = concatenate([text_embed, img_text_embed, img_embed])\n",
    "x = Dense(2048 + 150 + 150, activation='relu')(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "prediction = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "fcm_model = Model(inputs=[text_input, img_text_input, img_input], outputs=prediction)\n",
    "print(fcm_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
