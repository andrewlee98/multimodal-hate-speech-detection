{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import cv2\n",
    "import re\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make image dataloader using flow_from_dataframe\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# load data to extract labels\n",
    "data_dir = 'mmhs150k/'\n",
    "model_dir = 'models/'\n",
    "tweet_dict = json.load(open(data_dir + 'MMHS150K_GT.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 100)           7565100   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 150)               150600    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 7,715,851\n",
      "Trainable params: 150,751\n",
      "Non-trainable params: 7,565,100\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 8, 8, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              134218752 \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 156,546,849\n",
      "Trainable params: 156,512,417\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# load pretrained LSTM and CNN for text and images\n",
    "from keras.models import load_model\n",
    "\n",
    "lstm = load_model(model_dir + 'lstm.h5')\n",
    "cnn = load_model(model_dir + 'cnn.h5')\n",
    "\n",
    "print(lstm.summary())\n",
    "print(cnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 100)           7565100   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 150)               150600    \n",
      "=================================================================\n",
      "Total params: 7,715,700\n",
      "Trainable params: 150,600\n",
      "Non-trainable params: 7,565,100\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 8, 8, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 131072)            0         \n",
      "=================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create new models that are all but the last layer\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "text_net = Sequential()\n",
    "for layer in lstm.layers[:-1]: text_net.add(layer)\n",
    "print(text_net.summary())\n",
    "\n",
    "img_net = Sequential()\n",
    "for layer in cnn.layers[:-3]: img_net.add(layer)\n",
    "print(img_net.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 150)          7715700     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 131072)       21802784    input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 131372)       0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          67262976    concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            513         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 96,781,973\n",
      "Trainable params: 89,182,441\n",
      "Non-trainable params: 7,599,532\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# build full FCM model using concatenation layer\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers import Dense, Input\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "text_input = Input((text_net.layers[0].input_shape[-1],)) # get rid of None's in front\n",
    "img_text_input = Input((text_net.layers[0].input_shape[-1],))\n",
    "img_input = Input((img_net.layers[0].input_shape[1:])) # get rid of None in front\n",
    "\n",
    "text_embed = text_net(text_input)\n",
    "img_text_embed = text_net(img_text_input)\n",
    "img_embed = img_net(img_input)\n",
    "\n",
    "x = concatenate([text_embed, img_text_embed, img_embed])\n",
    "# x = Dense(2048 + 150 + 150, activation='relu')(x)\n",
    "# x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "prediction = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "fcm_model = Model(inputs=[text_input, img_text_input, img_input], outputs=prediction)\n",
    "print(fcm_model.summary())\n",
    "\n",
    "optimizer = Adam(lr = 0.001)\n",
    "fcm_model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method for cleaning text like in https://nlp.stanford.edu/projects/glove/preprocess-twitter.rb\n",
    "def hashtag(text):\n",
    "    hashtag_body = text.group()[1:]\n",
    "    if hashtag_body.isupper(): return \"<hashtag> {} \".format(hashtag_body.lower())\n",
    "    else: return ' '.join([\"<hashtag>\"] + [re.sub(r\"([A-Z])\",r\" \\1\", hashtag_body, flags=re.MULTILINE | re.DOTALL)])\n",
    "\n",
    "def allcaps(text): return text.group().lower() + ' <allcaps> '    \n",
    "\n",
    "def clean_tweet_text(t):\n",
    "    eyes = r'[8:=;]'\n",
    "    nose = r\"['`\\-]?\"\n",
    "    \n",
    "    t = re.sub(r'https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*', '<url>', t)\n",
    "    t = re.sub(r'@\\w+', '<user>', t)\n",
    "    t = re.sub(r'{}{}[)dD]+|[)dD]+{}{}'.format(eyes, nose, nose, eyes), '<smile>', t)\n",
    "    t = re.sub(r'{}{}p+\".format(eyes, nose)', '<lolface>', t)\n",
    "    t = re.sub(r'{}{}\\(+|\\)+{}{}'.format(eyes, nose, nose, eyes), '<sadface>', t)\n",
    "    t = re.sub(r'{}{}[\\/|l*]'.format(eyes, nose), '<neutralface>', t)\n",
    "    t = re.sub(r'/', ' / ', t)\n",
    "    t = re.sub(r'<3','<heart>', t)\n",
    "    t = re.sub(r'[-+]?[.\\d]*[\\d]+[:,.\\d]*', '<number>', t)\n",
    "    t = re.sub(r'#\\S+', hashtag, t)\n",
    "    t = re.sub(r'([!?.]){2,}', r'\\1 <repeat>', t)\n",
    "    t = re.sub(r'\\b(\\S*?)(.)\\2{2,}\\b', r'\\1\\2 <elong>', t)\n",
    "    t = re.sub(r'([A-Z]){2,}', allcaps, t)\n",
    "    t = re.sub(r'{}'.format(r'[\\\".,-;&:]'), ' ', t)\n",
    "    return t.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom data generator to handle multimodal data\n",
    "from random import randint # for random cropping\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "pad_len = text_net.layers[0].input_shape[-1]\n",
    "class MMDataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, splits_path, tweet_dict, tokenizer, pad_len, batch_size=32, dim=(299, 299), n_channels=3, \n",
    "                 shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.tweet_dict = tweet_dict\n",
    "        self.tokenizer = tokenizer\n",
    "        self.pad_len = pad_len\n",
    "        \n",
    "        # build labels list and id list\n",
    "        self.id_list = open(splits_path, 'r').read().splitlines()\n",
    "        self.labels = dict()\n",
    "        for id in self.id_list:\n",
    "            binary_labels = [1 if n > 0 else 0 for n in tweet_dict[id]['labels']]\n",
    "            label = 1 if sum(binary_labels)/len(tweet_dict[id]['labels']) > 0.5 else 0\n",
    "            self.labels[id] = label\n",
    "        \n",
    "        # create dictionary for embedded sequences (tuple of text and img_text)\n",
    "        self.text_dict = self.process_text(self.id_list)\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.id_list) / self.batch_size)) + 1 # last batch is partial\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:index*self.batch_size + self.batch_size]\n",
    "        \n",
    "        \n",
    "        # Find list of IDs\n",
    "        id_list_temp = [self.id_list[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X_txt, X_img_txt, X_img, y = self.__data_generation(id_list_temp)\n",
    "        \n",
    "#         print(X_txt.shape, X_img_txt.shape, X_img.shape, y.shape)\n",
    "        return [X_txt, X_img_txt, X_img], y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.id_list))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, id_list_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X_img = np.empty((len(id_list_temp), *self.dim, self.n_channels))\n",
    "        X_txt = np.empty((len(id_list_temp), self.pad_len))\n",
    "        X_img_txt = np.empty((len(id_list_temp), self.pad_len))\n",
    "        y = np.empty(len(id_list_temp), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(id_list_temp):\n",
    "            X_img[i,] = self.process_img(data_dir + 'img_resized/' + ID + '.jpg')\n",
    "            X_txt[i,] = self.text_dict[ID][0]\n",
    "            X_img_txt[i,] = self.text_dict[ID][1]\n",
    "\n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X_txt, X_img_txt, X_img, y\n",
    "    \n",
    "    def process_img(self, path): # method for getting image\n",
    "        img = Image.open(path)\n",
    "        img.load()\n",
    "        data = np.asarray(img, dtype='uint8')\n",
    "        im = self.augment(data)\n",
    "        \n",
    "        if im.shape==(self.dim[0], self.dim[1]): im = np.stack((im,)*3, axis=-1) # handle grayscale\n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def get_labels(self): # get list of labels for calculating AUROC\n",
    "        return [self.labels[ID] for ID in self.id_list]\n",
    "    \n",
    "    def augment(self, im): # random crop and random mirror\n",
    "        \n",
    "        # random crop\n",
    "        x_max, y_max = im.shape[0], im.shape[1]\n",
    "        x_start, y_start = randint(0, x_max - self.dim[0]), randint(0, y_max - self.dim[1])\n",
    "        im = im[x_start:x_start + self.dim[0], y_start:y_start + self.dim[1]]\n",
    "        \n",
    "        # random mirror\n",
    "        if randint(0,1): im = np.flip(im, axis=1)\n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def process_text(self,id_list):\n",
    "        \n",
    "        # matrix for texts\n",
    "        texts = [clean_tweet_text(tweet_dict[ID]['tweet_text']) for ID in id_list]\n",
    "        sequences = self.tokenizer.texts_to_sequences(texts)\n",
    "        text_seqs = pad_sequences(sequences, maxlen=self.pad_len)\n",
    "        \n",
    "        # matrix for img_texts\n",
    "        img_texts = []\n",
    "        for ID in id_list:\n",
    "            if os.path.exists(data_dir + 'img_txt/' + ID + '.json'):\n",
    "                img_txt = json.load(open(data_dir + 'img_txt/' + ID + '.json', 'r'))['img_text']\n",
    "                img_texts.append(img_txt)\n",
    "            else: img_texts.append('')\n",
    "        img_txt_sequences = self.tokenizer.texts_to_sequences(img_texts)\n",
    "        img_text_seqs = pad_sequences(img_txt_sequences, maxlen=self.pad_len) \n",
    "        \n",
    "        \n",
    "        id_to_seq = dict() # map id to text sequence compatible with embedding layer\n",
    "        for ID, txt, img_txt in zip(id_list, text_seqs, img_text_seqs):\n",
    "            id_to_seq[ID] = (txt, img_txt)\n",
    "        \n",
    "        return id_to_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data generators\n",
    "tokenizer = pickle.load(open(model_dir + 'tokenizer.pkl', 'rb'))\n",
    "pad_len = text_net.layers[0].input_shape[-1]\n",
    "\n",
    "train_gen = MMDataGenerator(splits_path=data_dir + 'splits/train_ids.txt',\n",
    "                          tweet_dict=tweet_dict,\n",
    "                          tokenizer=tokenizer,\n",
    "                          pad_len=pad_len,\n",
    "                          batch_size=32,\n",
    "                          dim=(299, 299),\n",
    "                          n_channels=3,\n",
    "                          shuffle=True)\n",
    "\n",
    "val_gen = MMDataGenerator(splits_path=data_dir + 'splits/val_ids.txt',\n",
    "                          tweet_dict=tweet_dict,\n",
    "                          tokenizer=tokenizer,\n",
    "                          pad_len=pad_len,\n",
    "                          batch_size=32,\n",
    "                          dim=(299, 299),\n",
    "                          n_channels=3,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_gen = MMDataGenerator(splits_path=data_dir + 'splits/test_ids.txt',\n",
    "                          tweet_dict=tweet_dict,\n",
    "                          tokenizer=tokenizer,\n",
    "                          pad_len=pad_len,\n",
    "                          batch_size=32,\n",
    "                          dim=(299, 299),\n",
    "                          n_channels=3,\n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " 707/4214 [====>.........................] - ETA: 2:03:53 - loss: 0.5081 - accuracy: 0.7913"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-96c6dcd64df9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     epochs=1)\n\u001b[0m",
      "\u001b[0;32m~/testenv/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/testenv/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/testenv/lib/python3.5/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/testenv/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/testenv/lib/python3.5/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/testenv/lib/python3.5/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/testenv/lib/python3.5/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/testenv/lib/python3.5/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/testenv/lib/python3.5/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/testenv/lib/python3.5/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train model\n",
    "history = fcm_model.fit_generator(train_gen,\n",
    "                    validation_data=val_gen,\n",
    "                    shuffle=True,\n",
    "                    epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
