{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import cv2\n",
    "import re\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make image dataloader using flow_from_dataframe\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# load data to extract labels\n",
    "data_dir = '../mmhs150k/'\n",
    "model_dir = 'models/'\n",
    "tweet_dict = json.load(open(data_dir + 'MMHS150K_GT.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 50, 100)           7565100   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 150)               150600    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 7,715,851\n",
      "Trainable params: 150,751\n",
      "Non-trainable params: 7,565,100\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 8, 8, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2048)              268437504 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 292,863,777\n",
      "Trainable params: 292,829,345\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# load pretrained LSTM and CNN for text and images\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "lstm = load_model(model_dir + 'lstm.h5')\n",
    "cnn = load_model(model_dir + 'cnn_weighted.h5')\n",
    "\n",
    "print(lstm.summary())\n",
    "print(cnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 50, 100)           7565100   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 150)               150600    \n",
      "=================================================================\n",
      "Total params: 7,715,700\n",
      "Trainable params: 150,600\n",
      "Non-trainable params: 7,565,100\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 8, 8, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2048)              268437504 \n",
      "=================================================================\n",
      "Total params: 290,240,288\n",
      "Trainable params: 290,205,856\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "283048"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new models that are all but the last layer\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "text_net = Sequential()\n",
    "for layer in lstm.layers[:-1]: text_net.add(layer)\n",
    "print(text_net.summary())\n",
    "\n",
    "img_net = Sequential()\n",
    "for layer in cnn.layers[:-3]: img_net.add(layer)\n",
    "print(img_net.summary())\n",
    "\n",
    "# free up memory from old models:\n",
    "del lstm\n",
    "del cnn\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 150)          7715700     input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 2048)         290240288   input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2348)         0           sequential_2[1][0]               \n",
      "                                                                 sequential_2[2][0]               \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2348)         5515452     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1024)         2405376     dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 512)          524800      dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            513         dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 306,402,129\n",
      "Trainable params: 298,802,597\n",
      "Non-trainable params: 7,599,532\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# build full FCM model using concatenation layer\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "text_input = Input((text_net.layers[0].input_shape[-1],)) # get rid of None's in front\n",
    "img_text_input = Input((text_net.layers[0].input_shape[-1],))\n",
    "img_input = Input((img_net.layers[0].input_shape[1:])) # get rid of None in front\n",
    "\n",
    "text_embed = text_net(text_input)\n",
    "img_text_embed = text_net(img_text_input)\n",
    "img_embed = img_net(img_input)\n",
    "\n",
    "x = concatenate([text_embed, img_text_embed, img_embed])\n",
    "x = Dense(2048 + 150 + 150, activation='relu')(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "prediction = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "fcm_model = Model(inputs=[text_input, img_text_input, img_input], outputs=prediction)\n",
    "print(fcm_model.summary())\n",
    "\n",
    "optimizer = Adam(lr = 1e-6)\n",
    "fcm_model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method for cleaning text like in https://nlp.stanford.edu/projects/glove/preprocess-twitter.rb\n",
    "def hashtag(text):\n",
    "    hashtag_body = text.group()[1:]\n",
    "    if hashtag_body.isupper(): return \"<hashtag> {} \".format(hashtag_body.lower())\n",
    "    else: return ' '.join([\"<hashtag>\"] + [re.sub(r\"([A-Z])\",r\" \\1\", hashtag_body, flags=re.MULTILINE | re.DOTALL)])\n",
    "\n",
    "def allcaps(text): return text.group().lower() + ' <allcaps> '    \n",
    "\n",
    "def clean_tweet_text(t):\n",
    "    eyes = r'[8:=;]'\n",
    "    nose = r\"['`\\-]?\"\n",
    "    \n",
    "    t = re.sub(r'https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*', '<url>', t)\n",
    "    t = re.sub(r'@\\w+', '<user>', t)\n",
    "    t = re.sub(r'{}{}[)dD]+|[)dD]+{}{}'.format(eyes, nose, nose, eyes), '<smile>', t)\n",
    "    t = re.sub(r'{}{}p+\".format(eyes, nose)', '<lolface>', t)\n",
    "    t = re.sub(r'{}{}\\(+|\\)+{}{}'.format(eyes, nose, nose, eyes), '<sadface>', t)\n",
    "    t = re.sub(r'{}{}[\\/|l*]'.format(eyes, nose), '<neutralface>', t)\n",
    "    t = re.sub(r'/', ' / ', t)\n",
    "    t = re.sub(r'<3','<heart>', t)\n",
    "    t = re.sub(r'[-+]?[.\\d]*[\\d]+[:,.\\d]*', '<number>', t)\n",
    "    t = re.sub(r'#\\S+', hashtag, t)\n",
    "    t = re.sub(r'([!?.]){2,}', r'\\1 <repeat>', t)\n",
    "    t = re.sub(r'\\b(\\S*?)(.)\\2{2,}\\b', r'\\1\\2 <elong>', t)\n",
    "    t = re.sub(r'([A-Z]){2,}', allcaps, t)\n",
    "    t = re.sub(r'{}'.format(r'[\\\".,-;&:]'), ' ', t)\n",
    "    return t.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom data generator to handle multimodal data\n",
    "from random import randint # for random cropping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "class MMDataGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, splits_path, tweet_dict, tokenizer, pad_len, batch_size=32, dim=(299, 299), n_channels=3, \n",
    "                 shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.tweet_dict = tweet_dict\n",
    "        self.tokenizer = tokenizer\n",
    "        self.pad_len = pad_len\n",
    "        \n",
    "        # build labels list and id list\n",
    "        self.id_list = open(splits_path, 'r').read().splitlines()\n",
    "        self.labels = dict()\n",
    "        for id in self.id_list:\n",
    "            binary_labels = [1 if n > 0 else 0 for n in tweet_dict[id]['labels']]\n",
    "            label = 1 if sum(binary_labels)/len(tweet_dict[id]['labels']) > 0.5 else 0\n",
    "            self.labels[id] = label\n",
    "        \n",
    "        # create dictionary for embedded sequences (tuple of text and img_text)\n",
    "        self.text_dict = self.process_text(self.id_list)\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "        self.classes = [self.labels[self.id_list[i]] for i in self.indexes]\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.id_list) / self.batch_size)) + 1 # last batch is partial\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:index*self.batch_size + self.batch_size]\n",
    "        \n",
    "        \n",
    "        # Find list of IDs\n",
    "        id_list_temp = [self.id_list[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X_txt, X_img_txt, X_img, y = self.__data_generation(id_list_temp)\n",
    "        \n",
    "        return [X_txt, X_img_txt, X_img], y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.id_list))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, id_list_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X_img = np.empty((len(id_list_temp), *self.dim, self.n_channels))\n",
    "        X_txt = np.empty((len(id_list_temp), self.pad_len))\n",
    "        X_img_txt = np.empty((len(id_list_temp), self.pad_len))\n",
    "        y = np.empty(len(id_list_temp), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(id_list_temp):\n",
    "            X_img[i,] = self.process_img(data_dir + 'img_resized/' + ID + '.jpg')\n",
    "            X_txt[i,] = self.text_dict[ID][0]\n",
    "            X_img_txt[i,] = self.text_dict[ID][1]\n",
    "\n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X_txt, X_img_txt, X_img, y\n",
    "    \n",
    "    def process_img(self, path): # method for getting image\n",
    "        img = Image.open(path)\n",
    "        img.load()\n",
    "        data = np.asarray(img, dtype='uint8')\n",
    "        im = self.augment(data)\n",
    "        \n",
    "        if im.shape==(self.dim[0], self.dim[1]): im = np.stack((im,)*3, axis=-1) # handle grayscale\n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def augment(self, im): # random crop and random mirror\n",
    "        \n",
    "        # random crop\n",
    "        x_max, y_max = im.shape[0], im.shape[1]\n",
    "        x_start, y_start = randint(0, x_max - self.dim[0]), randint(0, y_max - self.dim[1])\n",
    "        im = im[x_start:x_start + self.dim[0], y_start:y_start + self.dim[1]]\n",
    "        \n",
    "        # random mirror\n",
    "        if randint(0,1): im = np.flip(im, axis=1)\n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def process_text(self, id_list):\n",
    "        \n",
    "        # matrix for texts\n",
    "        texts = [clean_tweet_text(tweet_dict[ID]['tweet_text']) for ID in id_list]\n",
    "        sequences = self.tokenizer.texts_to_sequences(texts)\n",
    "        text_seqs = pad_sequences(sequences, maxlen=self.pad_len)\n",
    "        \n",
    "        # matrix for img_texts\n",
    "        img_texts = []\n",
    "        for ID in id_list:\n",
    "            if os.path.exists(data_dir + 'img_txt/' + ID + '.json'):\n",
    "                img_txt = json.load(open(data_dir + 'img_txt/' + ID + '.json', 'r'))['img_text']\n",
    "                img_texts.append(img_txt)\n",
    "            else: img_texts.append('')\n",
    "        img_txt_sequences = self.tokenizer.texts_to_sequences(img_texts)\n",
    "        img_text_seqs = pad_sequences(img_txt_sequences, maxlen=self.pad_len) \n",
    "        \n",
    "        \n",
    "        id_to_seq = dict() # map id to text sequence compatible with embedding layer\n",
    "        for ID, txt, img_txt in zip(id_list, text_seqs, img_text_seqs):\n",
    "            id_to_seq[ID] = (txt, img_txt)\n",
    "        \n",
    "        return id_to_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data generators\n",
    "tokenizer = pickle.load(open(model_dir + 'tokenizer.pkl', 'rb'))\n",
    "pad_len = 50#text_net.layers[0].input_shape[-1]\n",
    "\n",
    "train_gen = MMDataGenerator(splits_path=data_dir + 'splits/train_ids.txt',\n",
    "                          tweet_dict=tweet_dict,\n",
    "                          tokenizer=tokenizer,\n",
    "                          pad_len=pad_len,\n",
    "                          batch_size=32,\n",
    "                          dim=(299, 299),\n",
    "                          n_channels=3,\n",
    "                          shuffle=True)\n",
    "\n",
    "val_gen = MMDataGenerator(splits_path=data_dir + 'splits/val_ids.txt',\n",
    "                          tweet_dict=tweet_dict,\n",
    "                          tokenizer=tokenizer,\n",
    "                          pad_len=pad_len,\n",
    "                          batch_size=32,\n",
    "                          dim=(299, 299),\n",
    "                          n_channels=3,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_gen = MMDataGenerator(splits_path=data_dir + 'splits/test_ids.txt',\n",
    "                          tweet_dict=tweet_dict,\n",
    "                          tokenizer=tokenizer,\n",
    "                          pad_len=pad_len,\n",
    "                          batch_size=32,\n",
    "                          dim=(299, 299),\n",
    "                          n_channels=3,\n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "4214/4214 [==============================] - 7721s 2s/step - loss: 0.4840 - accuracy: 0.7849 - val_loss: 0.7733 - val_accuracy: 0.5454\n",
      "Epoch 2/8\n",
      "4214/4214 [==============================] - 7762s 2s/step - loss: 0.4558 - accuracy: 0.7948 - val_loss: 0.7617 - val_accuracy: 0.5782\n",
      "Epoch 3/8\n",
      "4214/4214 [==============================] - 7761s 2s/step - loss: 0.4498 - accuracy: 0.7998 - val_loss: 0.8254 - val_accuracy: 0.5554\n",
      "Epoch 4/8\n",
      "4214/4214 [==============================] - 7772s 2s/step - loss: 0.4479 - accuracy: 0.8006 - val_loss: 0.7508 - val_accuracy: 0.6038\n",
      "Epoch 5/8\n",
      "4214/4214 [==============================] - 8308s 2s/step - loss: 0.4454 - accuracy: 0.8016 - val_loss: 0.7600 - val_accuracy: 0.5966\n",
      "Epoch 6/8\n",
      "4214/4214 [==============================] - 7817s 2s/step - loss: 0.4444 - accuracy: 0.8019 - val_loss: 0.7659 - val_accuracy: 0.5946\n",
      "Epoch 7/8\n",
      "4214/4214 [==============================] - 7638s 2s/step - loss: 0.4432 - accuracy: 0.8026 - val_loss: 0.7548 - val_accuracy: 0.6012\n",
      "Epoch 8/8\n",
      "4214/4214 [==============================] - 7671s 2s/step - loss: 0.4425 - accuracy: 0.8032 - val_loss: 0.7241 - val_accuracy: 0.6250\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "mcp_save = ModelCheckpoint(model_dir + 'best_fcm.h5', save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "\n",
    "history = fcm_model.fit_generator(train_gen,\n",
    "                    validation_data=val_gen,\n",
    "                    shuffle=True,\n",
    "                    epochs=8,\n",
    "                    callbacks=[mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUROC: 0.73283622\n",
      "Test Accuracy: 0.6185\n",
      "Test F1: 0.4536732063582988\n",
      "Test Precision: 0.7987897125567323\n",
      "Test Recall: 0.3168\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score\n",
    "import math\n",
    "\n",
    "y_test = test_gen.classes\n",
    "\n",
    "# get AUROC\n",
    "preds = fcm_model.predict_generator(test_gen)\n",
    "print('Test AUROC:', roc_auc_score(y_test, preds))\n",
    "\n",
    "# get loss and acc\n",
    "preds_bin = np.array(preds)\n",
    "preds_bin[preds>0.5] = 1\n",
    "preds_bin[preds<=0.5] = 0\n",
    "print('Test Accuracy:', accuracy_score(y_test, preds_bin))\n",
    "\n",
    "# get F1\n",
    "print('Test F1:', f1_score(y_test, preds_bin, zero_division=1))\n",
    "print('Test Precision:', precision_score(y_test, preds_bin, zero_division=1))\n",
    "print('Test Recall:', recall_score(y_test, preds_bin, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# del text_net\n",
    "# del img_net\n",
    "# gc.collect()\n",
    "\n",
    "fcm_model = load_model(model_dir + 'fcm_with_weighted_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6728\n",
      "Test F1: 0.691727906538534\n",
      "Test Precision: 0.6539009618810118\n",
      "Test Recall: 0.7342\n"
     ]
    }
   ],
   "source": [
    "# get loss and acc\n",
    "preds_bin = np.array(preds)\n",
    "preds_bin[preds>0.2] = 1\n",
    "preds_bin[preds<=0.2] = 0\n",
    "print('Test Accuracy:', accuracy_score(y_test, preds_bin))\n",
    "\n",
    "# get F1\n",
    "print('Test F1:', f1_score(y_test, preds_bin, zero_division=1))\n",
    "print('Test Precision:', precision_score(y_test, preds_bin, zero_division=1))\n",
    "print('Test Recall:', recall_score(y_test, preds_bin, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcm_model.save(model_dir + 'fcm_with_weighted_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test the data generator\n",
    "X, ys = train_gen.__getitem__(0)\n",
    "texts, img_texts, imgs = X\n",
    "ids = train_gen.id_list[:32]\n",
    "\n",
    "for ID, text, img_text, img, y in list(zip(ids, texts, img_texts, imgs, ys))[:3]:\n",
    "    print(ID)\n",
    "    print(text)\n",
    "    print(img_text)\n",
    "    img = Image.fromarray(np.uint8(img), 'RGB')\n",
    "    display(img)\n",
    "    print('label:', y, '\\n\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
