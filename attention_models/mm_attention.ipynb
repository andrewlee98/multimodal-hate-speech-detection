{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import cv2\n",
    "import re\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# load data to extract labels\n",
    "data_dir = '../mmhs150k/'\n",
    "model_dir = '../fcm_replication/models/' # grab pretrained models from FCM\n",
    "tweet_dict = json.load(open(data_dir + 'MMHS150K_GT.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 50, 100)           7565100   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 150)               150600    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 7,715,851\n",
      "Trainable params: 150,751\n",
      "Non-trainable params: 7,565,100\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 8, 8, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2048)              268437504 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 292,863,777\n",
      "Trainable params: 292,829,345\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# load pretrained cnn\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "lstm = load_model(model_dir + 'lstm.h5')\n",
    "cnn = load_model(model_dir + 'cnn_weighted.h5')\n",
    "\n",
    "print(lstm.summary())\n",
    "print(cnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 50, 100)           7565100   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 150)               150600    \n",
      "=================================================================\n",
      "Total params: 7,715,700\n",
      "Trainable params: 150,600\n",
      "Non-trainable params: 7,565,100\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 8, 8, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2048)              268437504 \n",
      "=================================================================\n",
      "Total params: 290,240,288\n",
      "Trainable params: 290,205,856\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "283048"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new models that are all but the last layer\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "text_net = Sequential()\n",
    "for layer in lstm.layers[:-1]: text_net.add(layer)\n",
    "print(text_net.summary())\n",
    "\n",
    "img_net = Sequential()\n",
    "for layer in cnn.layers[:-3]: img_net.add(layer)\n",
    "print(img_net.summary())\n",
    "\n",
    "# free up memory from old models:\n",
    "del lstm\n",
    "del cnn\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method for cleaning text like in https://nlp.stanford.edu/projects/glove/preprocess-twitter.rb\n",
    "def hashtag(text):\n",
    "    hashtag_body = text.group()[1:]\n",
    "    if hashtag_body.isupper(): return \"<hashtag> {} \".format(hashtag_body.lower())\n",
    "    else: return ' '.join([\"<hashtag>\"] + [re.sub(r\"([A-Z])\",r\" \\1\", hashtag_body, flags=re.MULTILINE | re.DOTALL)])\n",
    "\n",
    "def allcaps(text): return text.group().lower() + ' <allcaps> '    \n",
    "\n",
    "def clean_tweet_text(t):\n",
    "    eyes = r'[8:=;]'\n",
    "    nose = r\"['`\\-]?\"\n",
    "    \n",
    "    t = re.sub(r'https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*', '<url>', t)\n",
    "    t = re.sub(r'@\\w+', '<user>', t)\n",
    "    t = re.sub(r'{}{}[)dD]+|[)dD]+{}{}'.format(eyes, nose, nose, eyes), '<smile>', t)\n",
    "    t = re.sub(r'{}{}p+\".format(eyes, nose)', '<lolface>', t)\n",
    "    t = re.sub(r'{}{}\\(+|\\)+{}{}'.format(eyes, nose, nose, eyes), '<sadface>', t)\n",
    "    t = re.sub(r'{}{}[\\/|l*]'.format(eyes, nose), '<neutralface>', t)\n",
    "    t = re.sub(r'/', ' / ', t)\n",
    "    t = re.sub(r'<3','<heart>', t)\n",
    "    t = re.sub(r'[-+]?[.\\d]*[\\d]+[:,.\\d]*', '<number>', t)\n",
    "    t = re.sub(r'#\\S+', hashtag, t)\n",
    "    t = re.sub(r'([!?.]){2,}', r'\\1 <repeat>', t)\n",
    "    t = re.sub(r'\\b(\\S*?)(.)\\2{2,}\\b', r'\\1\\2 <elong>', t)\n",
    "    t = re.sub(r'([A-Z]){2,}', allcaps, t)\n",
    "    t = re.sub(r'{}'.format(r'[\\\".,-;&:]'), ' ', t)\n",
    "    return t.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom data generator to handle multimodal data\n",
    "from random import randint # for random cropping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "class MMSeqDataGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, splits_path, tweet_dict, tokenizer, pad_len, batch_size=32, dim=(299, 299), n_channels=3, \n",
    "                 shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.tweet_dict = tweet_dict\n",
    "        self.tokenizer = tokenizer\n",
    "        self.pad_len = pad_len\n",
    "        \n",
    "        # build labels list and id list\n",
    "        self.id_list = open(splits_path, 'r').read().splitlines()\n",
    "        self.labels = dict()\n",
    "        for id in self.id_list:\n",
    "            binary_labels = [1 if n > 0 else 0 for n in tweet_dict[id]['labels']]\n",
    "            label = 1 if sum(binary_labels)/len(tweet_dict[id]['labels']) > 0.5 else 0\n",
    "            self.labels[id] = label\n",
    "        \n",
    "        # create dictionary for embedded sequences (tuple of text and img_text)\n",
    "        self.text_dict = self.process_text(self.id_list)\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "        self.classes = [self.labels[self.id_list[i]] for i in self.indexes]\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.id_list) / self.batch_size)) + 1 # last batch is partial\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:index*self.batch_size + self.batch_size]\n",
    "        \n",
    "        \n",
    "        # Find list of IDs\n",
    "        id_list_temp = [self.id_list[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X_txt, X_img_txt, X_img, y = self.__data_generation(id_list_temp)\n",
    "        \n",
    "        return [X_txt, X_img_txt, X_img], y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.id_list))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, id_list_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X_img = np.empty((len(id_list_temp), *self.dim, self.n_channels))\n",
    "        X_txt = np.empty((len(id_list_temp), self.pad_len))\n",
    "        X_img_txt = np.empty((len(id_list_temp), self.pad_len))\n",
    "        y = np.empty(len(id_list_temp), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(id_list_temp):\n",
    "            X_img[i,] = self.process_img(data_dir + 'img_resized/' + ID + '.jpg')\n",
    "            X_txt[i,] = self.text_dict[ID][0]\n",
    "            X_img_txt[i,] = self.text_dict[ID][1]\n",
    "\n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X_txt, X_img_txt, X_img, y\n",
    "    \n",
    "    def process_img(self, path): # method for getting image\n",
    "        img = Image.open(path)\n",
    "        img.load()\n",
    "        data = np.asarray(img, dtype='uint8')\n",
    "        im = self.augment(data)\n",
    "        \n",
    "        if im.shape==(self.dim[0], self.dim[1]): im = np.stack((im,)*3, axis=-1) # handle grayscale\n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def augment(self, im): # random crop and random mirror\n",
    "        \n",
    "        # random crop\n",
    "        x_max, y_max = im.shape[0], im.shape[1]\n",
    "        x_start, y_start = randint(0, x_max - self.dim[0]), randint(0, y_max - self.dim[1])\n",
    "        im = im[x_start:x_start + self.dim[0], y_start:y_start + self.dim[1]]\n",
    "        \n",
    "        # random mirror\n",
    "        if randint(0,1): im = np.flip(im, axis=1)\n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def process_text(self, id_list): # return \n",
    "        \n",
    "        # matrix for texts\n",
    "        texts = [clean_tweet_text(tweet_dict[ID]['tweet_text']) for ID in id_list]\n",
    "        sequences = self.tokenizer.texts_to_sequences(texts)\n",
    "        text_seqs = pad_sequences(sequences, maxlen=self.pad_len)\n",
    "        \n",
    "        # matrix for img_texts\n",
    "        img_texts = []\n",
    "        for ID in id_list:\n",
    "            if os.path.exists(data_dir + 'img_txt/' + ID + '.json'):\n",
    "                img_txt = json.load(open(data_dir + 'img_txt/' + ID + '.json', 'r'))['img_text']\n",
    "                img_texts.append(img_txt)\n",
    "            else: img_texts.append('')\n",
    "        img_txt_sequences = self.tokenizer.texts_to_sequences(img_texts)\n",
    "        img_text_seqs = pad_sequences(img_txt_sequences, maxlen=self.pad_len) \n",
    "        \n",
    "        \n",
    "        id_to_seq = dict() # map id to text sequence compatible with embedding layer\n",
    "        for ID, txt, img_txt in zip(id_list, text_seqs, img_text_seqs):\n",
    "            id_to_seq[ID] = (txt, img_txt)\n",
    "        \n",
    "        return id_to_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data generators\n",
    "tokenizer = pickle.load(open(model_dir + 'tokenizer.pkl', 'rb'))\n",
    "pad_len = text_net.layers[0].input_shape[-1]\n",
    "\n",
    "train_gen = MMSeqDataGenerator(splits_path=data_dir + 'splits/train_ids.txt',\n",
    "                          tweet_dict=tweet_dict,\n",
    "                          tokenizer=tokenizer,\n",
    "                          pad_len=pad_len,\n",
    "                          batch_size=32,\n",
    "                          dim=(299, 299),\n",
    "                          n_channels=3,\n",
    "                          shuffle=True)\n",
    "\n",
    "val_gen = MMSeqDataGenerator(splits_path=data_dir + 'splits/val_ids.txt',\n",
    "                          tweet_dict=tweet_dict,\n",
    "                          tokenizer=tokenizer,\n",
    "                          pad_len=pad_len,\n",
    "                          batch_size=32,\n",
    "                          dim=(299, 299),\n",
    "                          n_channels=3,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_gen = MMSeqDataGenerator(splits_path=data_dir + 'splits/test_ids.txt',\n",
    "                          tweet_dict=tweet_dict,\n",
    "                          tokenizer=tokenizer,\n",
    "                          pad_len=pad_len,\n",
    "                          batch_size=32,\n",
    "                          dim=(299, 299),\n",
    "                          n_channels=3,\n",
    "                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build same embedding matrix as in the lstm file\n",
    "from tensorflow.keras.layers import Dense, Input, Embedding, Conv1D\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "word_index = word_index = tokenizer.word_index\n",
    "MAX_SEQ_LEN = pad_len\n",
    "\n",
    "# map word to embedding\n",
    "embeddings_index = {}\n",
    "for line in open(os.path.join('..', 'glove.twitter.27B.100d.txt')):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    embeddings_index[word] = np.asarray(values[1:], dtype='float32')\n",
    "\n",
    "# create embedding matrix (words without embeddings get zero embeddings)\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "\n",
    "token_embedding = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQ_LEN,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Attention Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # MY SIMPLE CONCATENATION\n",
    "\n",
    "# # build attention model with image vector as query\n",
    "# # https://www.tensorflow.org/api_docs/python/tf/keras/layers/Attention\n",
    "# from tensorflow.keras.layers import concatenate, Attention, Reshape\n",
    "# from tensorflow.keras.layers import Dense, Input, Embedding, Conv1D\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# attention_dim = 256 # 256 in fb paper\n",
    "\n",
    "# #inputs\n",
    "# text_input = Input((text_net.layers[0].input_shape[-1],)) # get rid of None's in front, context/value\n",
    "# img_text_input = Input((text_net.layers[0].input_shape[-1],))\n",
    "# img_input = Input((img_net.layers[0].input_shape[1:])) # get rid of None's in front, query\n",
    "\n",
    "# # get [batch_size, Tq, dim] embeddings from text\n",
    "# txt_value_embeddings = token_embedding(text_input)\n",
    "# transformed_txt_value_embeddings = Dense(attention_dim)(txt_value_embeddings) # get more dimensions from text\n",
    "# cnn_layer = Conv1D(filters=attention_dim, kernel_size=4) # 1D conv for getting seq from txt\n",
    "# txt_value_seq_encoding = cnn_layer(transformed_txt_value_embeddings)\n",
    "\n",
    "# # get [batch_size, Tv, dim] embeddings from image\n",
    "# img_embed = img_net(img_input) # this is the query\n",
    "# img_query_seq_encoding = Dense(attention_dim)(img_embed) # linear activation to get same dimension\n",
    "\n",
    "# # FCM embeddings\n",
    "# img_text_embed = text_net(img_text_input)\n",
    "# text_embed = text_net(text_input)\n",
    "\n",
    "# # do attention input to DNN as in link\n",
    "# query_value_attention_seq = tf.keras.layers.Attention()(\n",
    "#     [img_query_seq_encoding, txt_value_seq_encoding])\n",
    "# query_encoding = img_query_seq_encoding\n",
    "# query_value_attention = tf.keras.layers.GlobalAveragePooling1D()(\n",
    "#     query_value_attention_seq)\n",
    "# input_layer = tf.keras.layers.Concatenate()(\n",
    "#     [query_encoding, query_value_attention, text_embed, img_text_embed, img_embed])\n",
    "\n",
    "# x = Dense(2048, activation='relu')(input_layer)\n",
    "# x = Dense(1024, activation='relu')(x)\n",
    "# x = Dense(512, activation='relu')(x)\n",
    "# prediction = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# model = Model(inputs=[text_input, img_text_input, img_input], outputs=prediction)\n",
    "# print(model.summary())\n",
    "\n",
    "# optimizer = Adam(lr = 1e-6)\n",
    "# model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symmetric Gated Model\n",
    "##### https://www.aclweb.org/anthology/P18-1185.pdf page 1994"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 50, 100)           7565100   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50, 256)           25856     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50, 256)           65792     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 46, 256)           327936    \n",
      "=================================================================\n",
      "Total params: 7,984,684\n",
      "Trainable params: 419,584\n",
      "Non-trainable params: 7,565,100\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23333"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pretrained text CNN\n",
    "\n",
    "pretrained_text_cnn = load_model(model_dir + 'best_text_cnn256_model.h5')\n",
    "\n",
    "text_cnn = Sequential()\n",
    "for layer in pretrained_text_cnn.layers[:-5]: text_cnn.add(layer)\n",
    "print(text_cnn.summary())\n",
    "\n",
    "del pretrained_text_cnn\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 2048)         290240288   input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          524544      sequential_1[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 46, 256)      7984684     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, None, 256)    0           dense[0][0]                      \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65536       global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          65536       global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          65792       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          65536       global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 256)          65792       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 256)          0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 256)          0           dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 256)          0           dense_5[0][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 256)          0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 256)          0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 256)          0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 256)          0           activation[0][0]                 \n",
      "                                                                 global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 256)          0           activation_1[0][0]               \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 150)          7715700     input_2[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 256)          0           multiply[0][0]                   \n",
      "                                                                 multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2604)         0           sequential[2][0]                 \n",
      "                                                                 sequential[1][0]                 \n",
      "                                                                 sequential_1[1][0]               \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 2048)         5335040     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1024)         2098176     dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 512)          524800      dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1)            513         dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 314,817,729\n",
      "Trainable params: 299,653,097\n",
      "Non-trainable params: 15,164,632\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## SYMMETRIC GATED MODEL\n",
    "\n",
    "# build attention model with image vector as query\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Attention\n",
    "from tensorflow.keras.layers import concatenate, Attention, Reshape, Dense, Input, Embedding, Conv1D, Add, Activation, Multiply\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import activations\n",
    "\n",
    "attention_dim = 256 # 256 in fb paper\n",
    "\n",
    "#inputs\n",
    "text_input = Input((text_net.layers[0].input_shape[-1],)) # get rid of None's in front, context/value\n",
    "img_text_input = Input((text_net.layers[0].input_shape[-1],))\n",
    "img_input = Input((img_net.layers[0].input_shape[1:])) # get rid of None's in front, query\n",
    "\n",
    "# FCM embeddings\n",
    "img_text_embed = text_net(img_text_input)\n",
    "text_embed = text_net(text_input)\n",
    "\n",
    "# get [batch_size, Tq, dim] embeddings from text\n",
    "t_prime = text_cnn(text_input)\n",
    "\n",
    "# get [batch_size, Tv, dim] embeddings from image\n",
    "img_embed = img_net(img_input) # this is the query\n",
    "g_prime = Dense(attention_dim)(img_embed) # linear activation to get same dimension\n",
    "\n",
    "# do attention input to DNN as in link\n",
    "a = tf.keras.layers.Attention()([g_prime, t_prime])\n",
    "a = tf.keras.layers.GlobalAveragePooling1D()(a)\n",
    "\n",
    "# symmetric-gated fusion\n",
    "gate_dim = 256\n",
    "\n",
    "beta_a = Add()([Dense(gate_dim, use_bias=False)(a), Dense(gate_dim)(g_prime)]) \n",
    "beta_a = Activation(activations.relu)(beta_a) # sigma(W_a * a + U_a * g' + b_a)\n",
    "\n",
    "beta_g = Add()([Dense(gate_dim, use_bias=False)(a), Dense(gate_dim)(g_prime)]) \n",
    "beta_g = Activation(activations.relu)(beta_g) # sigma(W_g * a + U_g * g' + b_g)\n",
    "\n",
    "m = Add()([Dense(gate_dim, use_bias=False)(a), Dense(gate_dim)(g_prime)]) # sigma(W_m * a + U_m * g' + b_m)\n",
    "m = Activation(activations.tanh)(m)\n",
    "\n",
    "f = Add()([Multiply()([beta_a, a]), Multiply()([beta_g, m])])\n",
    "\n",
    "\n",
    "# concatenate it all together\n",
    "input_layer = tf.keras.layers.Concatenate()([text_embed, img_text_embed, img_embed, f])\n",
    "\n",
    "x = Dense(2048, activation='relu')(input_layer)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "prediction = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=[text_input, img_text_input, img_input], outputs=prediction)\n",
    "print(model.summary())\n",
    "\n",
    "optimizer = Adam(lr = 1e-6)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "4214/4214 [==============================] - 9048s 2s/step - loss: 0.4747 - accuracy: 0.7888 - val_loss: 0.8025 - val_accuracy: 0.5640\n",
      "Epoch 2/8\n",
      "4214/4214 [==============================] - 8945s 2s/step - loss: 0.4590 - accuracy: 0.7952 - val_loss: 0.8066 - val_accuracy: 0.5794\n",
      "Epoch 3/8\n",
      "4214/4214 [==============================] - 9172s 2s/step - loss: 0.4552 - accuracy: 0.7972 - val_loss: 0.7520 - val_accuracy: 0.5874\n",
      "Epoch 4/8\n",
      "4214/4214 [==============================] - 8918s 2s/step - loss: 0.4527 - accuracy: 0.7972 - val_loss: 0.7996 - val_accuracy: 0.5810\n",
      "Epoch 5/8\n",
      "4214/4214 [==============================] - 8853s 2s/step - loss: 0.4511 - accuracy: 0.7986 - val_loss: 0.7556 - val_accuracy: 0.6018\n",
      "Epoch 6/8\n",
      "4214/4214 [==============================] - 8880s 2s/step - loss: 0.4484 - accuracy: 0.8002 - val_loss: 0.7852 - val_accuracy: 0.5882\n",
      "Epoch 7/8\n",
      "4214/4214 [==============================] - 8939s 2s/step - loss: 0.4475 - accuracy: 0.8009 - val_loss: 0.7695 - val_accuracy: 0.5924\n",
      "Epoch 8/8\n",
      "4214/4214 [==============================] - 8879s 2s/step - loss: 0.4464 - accuracy: 0.8009 - val_loss: 0.8057 - val_accuracy: 0.5634\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "mcp_save = ModelCheckpoint(model_dir + 'best_gated_att_pretrained_cnn.h5', \n",
    "                           save_best_only=True, \n",
    "                           monitor='val_loss', \n",
    "                           mode='min', \n",
    "                           save_weights_only=True)\n",
    "\n",
    "history = model.fit_generator(train_gen,\n",
    "                    validation_data=val_gen,\n",
    "                    shuffle=True,\n",
    "                    epochs=8,\n",
    "                    callbacks=[mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(model_dir + 'best_gated_att_pretrained_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUROC: 0.7309297800000001\n",
      "Test Accuracy: 0.5909\n",
      "Test F1: 0.367990112776147\n",
      "Test Precision: 0.8085539714867617\n",
      "Test Recall: 0.2382\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score\n",
    "import math\n",
    "\n",
    "y_test = test_gen.classes\n",
    "\n",
    "# get AUROC\n",
    "preds = model.predict_generator(test_gen)\n",
    "print('Test AUROC:', roc_auc_score(y_test, preds))\n",
    "\n",
    "# get loss and acc\n",
    "preds_bin = np.array(preds)\n",
    "preds_bin[preds>0.5] = 1\n",
    "preds_bin[preds<=0.5] = 0\n",
    "print('Test Accuracy:', accuracy_score(y_test, preds_bin))\n",
    "\n",
    "# get F1\n",
    "print('Test F1:', f1_score(y_test, preds_bin, zero_division=1))\n",
    "print('Test Precision:', precision_score(y_test, preds_bin, zero_division=1))\n",
    "print('Test Recall:', recall_score(y_test, preds_bin, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6755\n",
      "Test F1: 0.6583131515215331\n",
      "Test Precision: 0.695130086724483\n",
      "Test Recall: 0.6252\n"
     ]
    }
   ],
   "source": [
    "# get loss and acc\n",
    "preds_bin = np.array(preds)\n",
    "preds_bin[preds>0.25] = 1\n",
    "preds_bin[preds<=0.25] = 0\n",
    "print('Test Accuracy:', accuracy_score(y_test, preds_bin))\n",
    "\n",
    "# get F1\n",
    "print('Test F1:', f1_score(y_test, preds_bin, zero_division=1))\n",
    "print('Test Precision:', precision_score(y_test, preds_bin, zero_division=1))\n",
    "print('Test Recall:', recall_score(y_test, preds_bin, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
