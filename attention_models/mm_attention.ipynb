{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import cv2\n",
    "import re\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# load data to extract labels\n",
    "data_dir = '../mmhs150k/'\n",
    "model_dir = '../fcm_replication/models/' # grab pretrained models from FCM\n",
    "tweet_dict = json.load(open(data_dir + 'MMHS150K_GT.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 50, 100)           7565100   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 150)               150600    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 7,715,851\n",
      "Trainable params: 150,751\n",
      "Non-trainable params: 7,565,100\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 8, 8, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2048)              268437504 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 292,863,777\n",
      "Trainable params: 292,829,345\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# load pretrained cnn\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "lstm = load_model(model_dir + 'lstm.h5')\n",
    "cnn = load_model(model_dir + 'cnn_weighted.h5')\n",
    "\n",
    "print(lstm.summary())\n",
    "print(cnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 50, 100)           7565100   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 150)               150600    \n",
      "=================================================================\n",
      "Total params: 7,715,700\n",
      "Trainable params: 150,600\n",
      "Non-trainable params: 7,565,100\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 8, 8, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2048)              268437504 \n",
      "=================================================================\n",
      "Total params: 290,240,288\n",
      "Trainable params: 290,205,856\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "283048"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new models that are all but the last layer\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "text_net = Sequential()\n",
    "for layer in lstm.layers[:-1]: text_net.add(layer)\n",
    "print(text_net.summary())\n",
    "\n",
    "img_net = Sequential()\n",
    "for layer in cnn.layers[:-3]: img_net.add(layer)\n",
    "print(img_net.summary())\n",
    "\n",
    "# free up memory from old models:\n",
    "del lstm\n",
    "del cnn\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method for cleaning text like in https://nlp.stanford.edu/projects/glove/preprocess-twitter.rb\n",
    "def hashtag(text):\n",
    "    hashtag_body = text.group()[1:]\n",
    "    if hashtag_body.isupper(): return \"<hashtag> {} \".format(hashtag_body.lower())\n",
    "    else: return ' '.join([\"<hashtag>\"] + [re.sub(r\"([A-Z])\",r\" \\1\", hashtag_body, flags=re.MULTILINE | re.DOTALL)])\n",
    "\n",
    "def allcaps(text): return text.group().lower() + ' <allcaps> '    \n",
    "\n",
    "def clean_tweet_text(t):\n",
    "    eyes = r'[8:=;]'\n",
    "    nose = r\"['`\\-]?\"\n",
    "    \n",
    "    t = re.sub(r'https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*', '<url>', t)\n",
    "    t = re.sub(r'@\\w+', '<user>', t)\n",
    "    t = re.sub(r'{}{}[)dD]+|[)dD]+{}{}'.format(eyes, nose, nose, eyes), '<smile>', t)\n",
    "    t = re.sub(r'{}{}p+\".format(eyes, nose)', '<lolface>', t)\n",
    "    t = re.sub(r'{}{}\\(+|\\)+{}{}'.format(eyes, nose, nose, eyes), '<sadface>', t)\n",
    "    t = re.sub(r'{}{}[\\/|l*]'.format(eyes, nose), '<neutralface>', t)\n",
    "    t = re.sub(r'/', ' / ', t)\n",
    "    t = re.sub(r'<3','<heart>', t)\n",
    "    t = re.sub(r'[-+]?[.\\d]*[\\d]+[:,.\\d]*', '<number>', t)\n",
    "    t = re.sub(r'#\\S+', hashtag, t)\n",
    "    t = re.sub(r'([!?.]){2,}', r'\\1 <repeat>', t)\n",
    "    t = re.sub(r'\\b(\\S*?)(.)\\2{2,}\\b', r'\\1\\2 <elong>', t)\n",
    "    t = re.sub(r'([A-Z]){2,}', allcaps, t)\n",
    "    t = re.sub(r'{}'.format(r'[\\\".,-;&:]'), ' ', t)\n",
    "    return t.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom data generator to handle multimodal data\n",
    "from random import randint # for random cropping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "class MMSeqDataGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, splits_path, tweet_dict, tokenizer, pad_len, batch_size=32, dim=(299, 299), n_channels=3, \n",
    "                 shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.tweet_dict = tweet_dict\n",
    "        self.tokenizer = tokenizer\n",
    "        self.pad_len = pad_len\n",
    "        \n",
    "        # build labels list and id list\n",
    "        self.id_list = open(splits_path, 'r').read().splitlines()\n",
    "        self.labels = dict()\n",
    "        for id in self.id_list:\n",
    "            binary_labels = [1 if n > 0 else 0 for n in tweet_dict[id]['labels']]\n",
    "            label = 1 if sum(binary_labels)/len(tweet_dict[id]['labels']) > 0.5 else 0\n",
    "            self.labels[id] = label\n",
    "        \n",
    "        # create dictionary for embedded sequences (tuple of text and img_text)\n",
    "        self.text_dict = self.process_text(self.id_list)\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "        self.classes = [self.labels[self.id_list[i]] for i in self.indexes]\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.id_list) / self.batch_size)) + 1 # last batch is partial\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:index*self.batch_size + self.batch_size]\n",
    "        \n",
    "        \n",
    "        # Find list of IDs\n",
    "        id_list_temp = [self.id_list[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X_txt, X_img_txt, X_img, y = self.__data_generation(id_list_temp)\n",
    "        \n",
    "        return [X_txt, X_img_txt, X_img], y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.id_list))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, id_list_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X_img = np.empty((len(id_list_temp), *self.dim, self.n_channels))\n",
    "        X_txt = np.empty((len(id_list_temp), self.pad_len))\n",
    "        X_img_txt = np.empty((len(id_list_temp), self.pad_len))\n",
    "        y = np.empty(len(id_list_temp), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(id_list_temp):\n",
    "            X_img[i,] = self.process_img(data_dir + 'img_resized/' + ID + '.jpg')\n",
    "            X_txt[i,] = self.text_dict[ID][0]\n",
    "            X_img_txt[i,] = self.text_dict[ID][1]\n",
    "\n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X_txt, X_img_txt, X_img, y\n",
    "    \n",
    "    def process_img(self, path): # method for getting image\n",
    "        img = Image.open(path)\n",
    "        img.load()\n",
    "        data = np.asarray(img, dtype='uint8')\n",
    "        im = self.augment(data)\n",
    "        \n",
    "        if im.shape==(self.dim[0], self.dim[1]): im = np.stack((im,)*3, axis=-1) # handle grayscale\n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def augment(self, im): # random crop and random mirror\n",
    "        \n",
    "        # random crop\n",
    "        x_max, y_max = im.shape[0], im.shape[1]\n",
    "        x_start, y_start = randint(0, x_max - self.dim[0]), randint(0, y_max - self.dim[1])\n",
    "        im = im[x_start:x_start + self.dim[0], y_start:y_start + self.dim[1]]\n",
    "        \n",
    "        # random mirror\n",
    "        if randint(0,1): im = np.flip(im, axis=1)\n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def process_text(self, id_list): # return \n",
    "        \n",
    "        # matrix for texts\n",
    "        texts = [clean_tweet_text(tweet_dict[ID]['tweet_text']) for ID in id_list]\n",
    "        sequences = self.tokenizer.texts_to_sequences(texts)\n",
    "        text_seqs = pad_sequences(sequences, maxlen=self.pad_len)\n",
    "        \n",
    "        # matrix for img_texts\n",
    "        img_texts = []\n",
    "        for ID in id_list:\n",
    "            if os.path.exists(data_dir + 'img_txt/' + ID + '.json'):\n",
    "                img_txt = json.load(open(data_dir + 'img_txt/' + ID + '.json', 'r'))['img_text']\n",
    "                img_texts.append(img_txt)\n",
    "            else: img_texts.append('')\n",
    "        img_txt_sequences = self.tokenizer.texts_to_sequences(img_texts)\n",
    "        img_text_seqs = pad_sequences(img_txt_sequences, maxlen=self.pad_len) \n",
    "        \n",
    "        \n",
    "        id_to_seq = dict() # map id to text sequence compatible with embedding layer\n",
    "        for ID, txt, img_txt in zip(id_list, text_seqs, img_text_seqs):\n",
    "            id_to_seq[ID] = (txt, img_txt)\n",
    "        \n",
    "        return id_to_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data generators\n",
    "tokenizer = pickle.load(open(model_dir + 'tokenizer.pkl', 'rb'))\n",
    "pad_len = text_net.layers[0].input_shape[-1]\n",
    "\n",
    "train_gen = MMSeqDataGenerator(splits_path=data_dir + 'splits/train_ids.txt',\n",
    "                          tweet_dict=tweet_dict,\n",
    "                          tokenizer=tokenizer,\n",
    "                          pad_len=pad_len,\n",
    "                          batch_size=32,\n",
    "                          dim=(299, 299),\n",
    "                          n_channels=3,\n",
    "                          shuffle=True)\n",
    "\n",
    "val_gen = MMSeqDataGenerator(splits_path=data_dir + 'splits/val_ids.txt',\n",
    "                          tweet_dict=tweet_dict,\n",
    "                          tokenizer=tokenizer,\n",
    "                          pad_len=pad_len,\n",
    "                          batch_size=32,\n",
    "                          dim=(299, 299),\n",
    "                          n_channels=3,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_gen = MMSeqDataGenerator(splits_path=data_dir + 'splits/test_ids.txt',\n",
    "                          tweet_dict=tweet_dict,\n",
    "                          tokenizer=tokenizer,\n",
    "                          pad_len=pad_len,\n",
    "                          batch_size=32,\n",
    "                          dim=(299, 299),\n",
    "                          n_channels=3,\n",
    "                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build same embedding matrix as in the lstm file\n",
    "from tensorflow.keras.layers import Dense, Input, Embedding, Conv1D\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "word_index = word_index = tokenizer.word_index\n",
    "MAX_SEQ_LEN = pad_len\n",
    "\n",
    "# map word to embedding\n",
    "embeddings_index = {}\n",
    "for line in open(os.path.join('..', 'glove.twitter.27B.100d.txt')):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    embeddings_index[word] = np.asarray(values[1:], dtype='float32')\n",
    "\n",
    "# create embedding matrix (words without embeddings get zero embeddings)\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "\n",
    "token_embedding = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQ_LEN,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Attention Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 100)      7565100     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 2048)         290240288   input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 50, 256)      25856       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          524544      sequential_1[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 47, 256)      262400      dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, None, 256)    0           dense_1[0][0]                    \n",
      "                                                                 conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 256)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 150)          7715700     input_2[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2860)         0           dense_1[0][0]                    \n",
      "                                                                 global_average_pooling1d[0][0]   \n",
      "                                                                 sequential[2][0]                 \n",
      "                                                                 sequential[1][0]                 \n",
      "                                                                 sequential_1[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2048)         5859328     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1024)         2098176     dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 512)          524800      dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            513         dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 314,816,705\n",
      "Trainable params: 299,652,073\n",
      "Non-trainable params: 15,164,632\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# # MY SIMPLE CONCATENATION\n",
    "\n",
    "# # build attention model with image vector as query\n",
    "# # https://www.tensorflow.org/api_docs/python/tf/keras/layers/Attention\n",
    "# from tensorflow.keras.layers import concatenate, Attention, Reshape\n",
    "# from tensorflow.keras.layers import Dense, Input, Embedding, Conv1D\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# attention_dim = 256 # 256 in fb paper\n",
    "\n",
    "# #inputs\n",
    "# text_input = Input((text_net.layers[0].input_shape[-1],)) # get rid of None's in front, context/value\n",
    "# img_text_input = Input((text_net.layers[0].input_shape[-1],))\n",
    "# img_input = Input((img_net.layers[0].input_shape[1:])) # get rid of None's in front, query\n",
    "\n",
    "# # get [batch_size, Tq, dim] embeddings from text\n",
    "# txt_value_embeddings = token_embedding(text_input)\n",
    "# transformed_txt_value_embeddings = Dense(attention_dim)(txt_value_embeddings) # get more dimensions from text\n",
    "# cnn_layer = Conv1D(filters=attention_dim, kernel_size=4) # 1D conv for getting seq from txt\n",
    "# txt_value_seq_encoding = cnn_layer(transformed_txt_value_embeddings)\n",
    "\n",
    "# # get [batch_size, Tv, dim] embeddings from image\n",
    "# img_embed = img_net(img_input) # this is the query\n",
    "# img_query_seq_encoding = Dense(attention_dim)(img_embed) # linear activation to get same dimension\n",
    "\n",
    "# # FCM embeddings\n",
    "# img_text_embed = text_net(img_text_input)\n",
    "# text_embed = text_net(text_input)\n",
    "\n",
    "# # do attention input to DNN as in link\n",
    "# query_value_attention_seq = tf.keras.layers.Attention()(\n",
    "#     [img_query_seq_encoding, txt_value_seq_encoding])\n",
    "# query_encoding = img_query_seq_encoding\n",
    "# query_value_attention = tf.keras.layers.GlobalAveragePooling1D()(\n",
    "#     query_value_attention_seq)\n",
    "# input_layer = tf.keras.layers.Concatenate()(\n",
    "#     [query_encoding, query_value_attention, text_embed, img_text_embed, img_embed])\n",
    "\n",
    "# x = Dense(2048, activation='relu')(input_layer)\n",
    "# x = Dense(1024, activation='relu')(x)\n",
    "# x = Dense(512, activation='relu')(x)\n",
    "# prediction = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# model = Model(inputs=[text_input, img_text_input, img_input], outputs=prediction)\n",
    "# print(model.summary())\n",
    "\n",
    "# optimizer = Adam(lr = 1e-6)\n",
    "# model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symmetric Gated Model\n",
    "##### https://www.aclweb.org/anthology/P18-1185.pdf page 1994"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 100)      7565100     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 2048)         290240288   input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 50, 256)      25856       embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 256)          524544      sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 47, 256)      262400      dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         (None, None, 256)    0           dense_9[0][0]                    \n",
      "                                                                 conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 256)          0           attention_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 256)          65792       global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 256)          65792       dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 256)          65792       global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 256)          65792       dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 256)          65792       global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 256)          65792       dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 256)          0           dense_10[0][0]                   \n",
      "                                                                 dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 256)          0           dense_12[0][0]                   \n",
      "                                                                 dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 256)          0           dense_14[0][0]                   \n",
      "                                                                 dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256)          0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 256)          0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 256)          0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 256)          0           activation_3[0][0]               \n",
      "                                                                 global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 256)          0           activation_4[0][0]               \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 150)          7715700     input_5[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 256)          0           multiply_1[0][0]                 \n",
      "                                                                 multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2604)         0           sequential[4][0]                 \n",
      "                                                                 sequential[3][0]                 \n",
      "                                                                 sequential_1[2][0]               \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 2048)         5335040     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1024)         2098176     dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 512)          524800      dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 1)            513         dense_18[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 314,687,169\n",
      "Trainable params: 299,522,537\n",
      "Non-trainable params: 15,164,632\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# SYMMETRIC GATED MODEL\n",
    "\n",
    "# build attention model with image vector as query\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Attention\n",
    "from tensorflow.keras.layers import concatenate, Attention, Reshape, Dense, Input, Embedding, Conv1D, Add, Activation, Multiply\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import activations\n",
    "\n",
    "attention_dim = 256 # 256 in fb paper\n",
    "\n",
    "#inputs\n",
    "text_input = Input((text_net.layers[0].input_shape[-1],)) # get rid of None's in front, context/value\n",
    "img_text_input = Input((text_net.layers[0].input_shape[-1],))\n",
    "img_input = Input((img_net.layers[0].input_shape[1:])) # get rid of None's in front, query\n",
    "\n",
    "# FCM embeddings\n",
    "img_text_embed = text_net(img_text_input)\n",
    "text_embed = text_net(text_input)\n",
    "\n",
    "# get [batch_size, Tq, dim] embeddings from text\n",
    "txt_value_embeddings = token_embedding(text_input)\n",
    "transformed_txt_value_embeddings = Dense(attention_dim)(txt_value_embeddings) # get more dimensions from text\n",
    "cnn_layer = Conv1D(filters=attention_dim, kernel_size=4) # 1D conv for getting seq from txt\n",
    "t_prime = cnn_layer(transformed_txt_value_embeddings)\n",
    "\n",
    "# get [batch_size, Tv, dim] embeddings from image\n",
    "img_embed = img_net(img_input) # this is the query\n",
    "g_prime = Dense(attention_dim)(img_embed) # linear activation to get same dimension\n",
    "\n",
    "# do attention input to DNN as in link\n",
    "a = tf.keras.layers.Attention()([g_prime, t_prime])\n",
    "a = tf.keras.layers.GlobalAveragePooling1D()(a)\n",
    "\n",
    "# symmetric-gated fusion\n",
    "gate_dim = 256\n",
    "\n",
    "beta_a1 = Dense(gate_dim)(a) # W_a * a\n",
    "beta_a2 = Dense(gate_dim)(g_prime) # U_a * g'\n",
    "beta_a = Add()([beta_a1, beta_a2]) \n",
    "beta_a = Activation(activations.relu)(beta_a) # sigma(W_a * a + U_a * g' + b_a)\n",
    "\n",
    "beta_g1 = Dense(gate_dim)(a) # W_g * a\n",
    "beta_g2 = Dense(gate_dim)(g_prime) # U_g * g'\n",
    "beta_g = Add()([beta_g1, beta_g2]) \n",
    "beta_g = Activation(activations.relu)(beta_g) # sigma(W_g * a + U_g * g' + b_g)\n",
    "\n",
    "m1 = Dense(gate_dim)(a) # W_m * a\n",
    "m2 = Dense(gate_dim)(g_prime) # U_m * g'\n",
    "m = Add()([m1, m2]) # sigma(W_m * a + U_m * g' + b_m)\n",
    "m = Activation(activations.tanh)(m)\n",
    "\n",
    "f1 = Multiply()([beta_a, a])\n",
    "f2 = Multiply()([beta_g, m])\n",
    "f = Add()([f1, f2])\n",
    "\n",
    "\n",
    "# concatenate it all together\n",
    "input_layer = tf.keras.layers.Concatenate()([text_embed, img_text_embed, img_embed, f])\n",
    "\n",
    "x = Dense(2048, activation='relu')(input_layer)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "prediction = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=[text_input, img_text_input, img_input], outputs=prediction)\n",
    "print(model.summary())\n",
    "\n",
    "optimizer = Adam(lr = 1e-6)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "4214/4214 [==============================] - 8607s 2s/step - loss: 0.4844 - accuracy: 0.7847 - val_loss: 0.8760 - val_accuracy: 0.5112\n",
      "Epoch 2/8\n",
      "4214/4214 [==============================] - 8727s 2s/step - loss: 0.4579 - accuracy: 0.7950 - val_loss: 0.7693 - val_accuracy: 0.5752\n",
      "Epoch 3/8\n",
      "4214/4214 [==============================] - 8399s 2s/step - loss: 0.4514 - accuracy: 0.7990 - val_loss: 0.7425 - val_accuracy: 0.5986\n",
      "Epoch 4/8\n",
      "4214/4214 [==============================] - 8443s 2s/step - loss: 0.4479 - accuracy: 0.8006 - val_loss: 0.7883 - val_accuracy: 0.5786\n",
      "Epoch 5/8\n",
      "4214/4214 [==============================] - 8035s 2s/step - loss: 0.4466 - accuracy: 0.8016 - val_loss: 0.8103 - val_accuracy: 0.5744\n",
      "Epoch 6/8\n",
      "4214/4214 [==============================] - 8131s 2s/step - loss: 0.4448 - accuracy: 0.8015 - val_loss: 0.8181 - val_accuracy: 0.5700\n",
      "Epoch 7/8\n",
      "4214/4214 [==============================] - 8024s 2s/step - loss: 0.4434 - accuracy: 0.8027 - val_loss: 0.7407 - val_accuracy: 0.6108\n",
      "Epoch 8/8\n",
      "4214/4214 [==============================] - 8010s 2s/step - loss: 0.4422 - accuracy: 0.8029 - val_loss: 0.7336 - val_accuracy: 0.6130\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "mcp_save = ModelCheckpoint(model_dir + 'best_gated_att.h5', \n",
    "                           save_best_only=True, \n",
    "                           monitor='val_loss', \n",
    "                           mode='min', \n",
    "                           save_weights_only=True)\n",
    "\n",
    "history = model.fit_generator(train_gen,\n",
    "                    validation_data=val_gen,\n",
    "                    shuffle=True,\n",
    "                    epochs=8,\n",
    "                    callbacks=[mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUROC: 0.7347106999999999\n",
      "Test Accuracy: 0.611\n",
      "Test F1: 0.43261376896149356\n",
      "Test Precision: 0.7990301724137931\n",
      "Test Recall: 0.2966\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score\n",
    "import math\n",
    "\n",
    "y_test = test_gen.classes\n",
    "\n",
    "# get AUROC\n",
    "preds = model.predict_generator(test_gen)\n",
    "print('Test AUROC:', roc_auc_score(y_test, preds))\n",
    "\n",
    "# get loss and acc\n",
    "preds_bin = np.array(preds)\n",
    "preds_bin[preds>0.5] = 1\n",
    "preds_bin[preds<=0.5] = 0\n",
    "print('Test Accuracy:', accuracy_score(y_test, preds_bin))\n",
    "\n",
    "# get F1\n",
    "print('Test F1:', f1_score(y_test, preds_bin, zero_division=1))\n",
    "print('Test Precision:', precision_score(y_test, preds_bin, zero_division=1))\n",
    "print('Test Recall:', recall_score(y_test, preds_bin, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6828\n",
      "Test F1: 0.6697897147616073\n",
      "Test Precision: 0.6984368215371255\n",
      "Test Recall: 0.6434\n"
     ]
    }
   ],
   "source": [
    "# get loss and acc\n",
    "preds_bin = np.array(preds)\n",
    "preds_bin[preds>0.25] = 1\n",
    "preds_bin[preds<=0.25] = 0\n",
    "print('Test Accuracy:', accuracy_score(y_test, preds_bin))\n",
    "\n",
    "# get F1\n",
    "print('Test F1:', f1_score(y_test, preds_bin, zero_division=1))\n",
    "print('Test Precision:', precision_score(y_test, preds_bin, zero_division=1))\n",
    "print('Test Recall:', recall_score(y_test, preds_bin, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
