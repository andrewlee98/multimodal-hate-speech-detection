{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "import gc\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8500\n",
      "500\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# create giant dictionary for all data\n",
    "data_dir = '../facebook_challenge_data/'\n",
    "model_dir = 'models/'\n",
    "\n",
    "# load data and print sizes\n",
    "def get_dict(path):\n",
    "    jsonl_content = open(path, 'r').read()\n",
    "    data = [json.loads(jline) for jline in jsonl_content.split('\\n')]\n",
    "    return {datum['id'] : datum for datum in data}\n",
    "\n",
    "\n",
    "train_dict = get_dict(data_dir + 'train.jsonl')\n",
    "val_dict = get_dict(data_dir + 'dev.jsonl')\n",
    "test_dict = get_dict(data_dir + 'test.jsonl')\n",
    "\n",
    "print(len(train_dict))\n",
    "print(len(val_dict))\n",
    "print(len(test_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "roberta (ROBERTA)            ((None, 50, 768), (None,  124645632 \n",
      "_________________________________________________________________\n",
      "tf_op_layer_strided_slice (T [(None, 1, 768)]          0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Squeeze (TensorF [(None, 768)]             0         \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "outputs (Dense)              (None, 1)                 769       \n",
      "=================================================================\n",
      "Total params: 124,646,401\n",
      "Trainable params: 124,646,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# load text_roberta\n",
    "import transformers\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "MAX_SEQ_LEN = 50\n",
    "\n",
    "class ROBERTA(transformers.TFRobertaModel):\n",
    "\n",
    "    def __init__(self, config, *inputs, **kwargs):\n",
    "        super(ROBERTA, self).__init__(config, *inputs, **kwargs)\n",
    "        self.roberta.call = tf.function(self.roberta.call)\n",
    "\n",
    "input_ids = layers.Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32)\n",
    "roberta = ROBERTA.from_pretrained('roberta-base')\n",
    "roberta_encodings = roberta([input_ids])[0]\n",
    "doc_encoding = tf.squeeze(roberta_encodings[:, 0:1, :], axis=1) # Keep [CLS] token encoding\n",
    "doc_encoding = layers.Dropout(0.1)(doc_encoding) # Apply dropout\n",
    "outputs = layers.Dense(1, activation='sigmoid', name='outputs')(doc_encoding)\n",
    "text_model = tf.keras.models.Model(inputs=[input_ids], outputs=[outputs])\n",
    "text_model.load_weights(model_dir + 'best_text_roberta_weights.h5')\n",
    "\n",
    "print(text_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet152 (Model)            (None, 7, 7, 2048)        58370944  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 60,994,433\n",
      "Trainable params: 2,623,489\n",
      "Non-trainable params: 58,370,944\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# load cnn\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "conv_base = tf.keras.applications.resnet.ResNet152(include_top=False, \n",
    "                                                        weights='imagenet', \n",
    "                                                        input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in conv_base.layers:\n",
    "    if isinstance(layer, layers.BatchNormalization): layer.trainable = True\n",
    "    else: layer.trainable = False\n",
    "\n",
    "\n",
    "img_model = Sequential()\n",
    "img_model.add(conv_base)\n",
    "img_model.add(layers.GlobalAveragePooling2D())\n",
    "img_model.add(Dense(1024, activation='relu'))\n",
    "img_model.add(Dense(512, activation='relu'))\n",
    "img_model.add(Dense(1, activation='sigmoid'))\n",
    "print(img_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet152 (Model)            (None, 7, 7, 2048)        58370944  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "=================================================================\n",
      "Total params: 60,993,920\n",
      "Trainable params: 2,622,976\n",
      "Non-trainable params: 58,370,944\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new models that are all but the last layer\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "img_net = Sequential()\n",
    "for layer in img_model.layers[:-1]: img_net.add(layer)\n",
    "print(img_net.summary())\n",
    "\n",
    "# free up memory from old models:\n",
    "del img_model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "roberta (ROBERTA)               ((None, 50, 768), (N 124645632   input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 1, 768)]     0           roberta[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze (TensorFlow [(None, 768)]        0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 768)          0           tf_op_layer_Squeeze[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 512)          60993920    input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1280)         0           dropout_38[0][0]                 \n",
      "                                                                 sequential_1[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1024)         1311744     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 512)          524800      dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            513         dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 187,476,609\n",
      "Trainable params: 129,105,665\n",
      "Non-trainable params: 58,370,944\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "img_input = layers.Input((img_net.layers[0].input_shape[1:]))\n",
    "img_embed = img_net(img_input)\n",
    "x = layers.concatenate([doc_encoding, img_embed])\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "prediction = layers.Dense(1, activation='sigmoid')(x)\n",
    "fcm_model = Model(inputs=[input_ids, img_input], outputs=prediction)\n",
    "print(fcm_model.summary())\n",
    "\n",
    "optimizer = Adam(lr = 1e-6)\n",
    "fcm_model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint # for random cropping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "class FBMMDataGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, data_dict, tokenizer, pad_len, batch_size=32, dim=(299, 299), n_channels=3, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.data_dict = data_dict\n",
    "        self.batch_size = batch_size\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.pad_len = pad_len\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        # build labels list and id list\n",
    "        self.id_list = list(self.data_dict.keys())\n",
    "        self.labels = {ID: self.data_dict[ID]['label'] for ID in self.id_list}\n",
    "        self.img_list = {ID: self.data_dict[ID]['img'] for ID in self.id_list}\n",
    "            \n",
    "        # get text dictionary\n",
    "        self.text_dict = self.process_text(self.id_list)\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "        self.classes = [self.labels[self.id_list[i]] for i in self.indexes]\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.id_list) / self.batch_size)) + 1 # last batch is partial\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:index*self.batch_size + self.batch_size]\n",
    "        \n",
    "        \n",
    "        # Find list of IDs\n",
    "        id_list_temp = [self.id_list[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X_txt, X_img, y = self.__data_generation(id_list_temp)\n",
    "        \n",
    "        return (X_txt, X_img), y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.id_list))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, id_list_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X_img = np.empty((len(id_list_temp), *self.dim, self.n_channels))\n",
    "        X_txt = np.empty((len(id_list_temp), self.pad_len))\n",
    "        y = np.empty(len(id_list_temp), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(id_list_temp):\n",
    "            # Store sample\n",
    "            X_img[i,] = self.process_img(data_dir + self.img_list[ID])\n",
    "            X_txt[i,] = self.text_dict[ID]\n",
    "\n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X_txt.astype(int), X_img, y\n",
    "    \n",
    "    def process_img(self, path): # method for getting image\n",
    "        img = Image.open(path)\n",
    "        img.load()\n",
    "        img = img.resize(self.dim, Image.ANTIALIAS)\n",
    "        data = np.asarray(img, dtype='uint8')\n",
    "        im = self.augment(data)\n",
    "        \n",
    "        \n",
    "        if im.shape==(self.dim[0], self.dim[1]): im = np.stack((im,)*3, axis=-1) # handle grayscale\n",
    "        if im.shape == (*self.dim, 4): im = im[:,:,:3] # handle weird case\n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def augment(self, im): # random crop and random mirror\n",
    "        \n",
    "        # random crop\n",
    "        x_max, y_max = im.shape[0], im.shape[1]\n",
    "        x_start, y_start = randint(0, x_max - self.dim[0]), randint(0, y_max - self.dim[1])\n",
    "        im = im[x_start:x_start + self.dim[0], y_start:y_start + self.dim[1]]\n",
    "        \n",
    "        # random mirror\n",
    "        if randint(0,1): im = np.flip(im, axis=1)\n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def process_text(self, id_list):\n",
    "        \n",
    "        # matrix for texts\n",
    "        texts = [self.data_dict[ID]['text'] for ID in id_list]\n",
    "        sequences = [self.tokenizer.encode(text) for text in texts] # make this more efficient...\n",
    "        text_seqs = pad_sequences(sequences, maxlen=self.pad_len)\n",
    "        \n",
    "        id_to_seq = {ID: txt for (ID, txt) in zip(id_list, text_seqs)} # map id to text seq\n",
    "        \n",
    "        return id_to_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, TFRobertaModel\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "max_len = 50\n",
    "\n",
    "# create data generators\n",
    "train_gen = FBMMDataGenerator(data_dict=train_dict,\n",
    "                          tokenizer=tokenizer,\n",
    "                          pad_len=max_len,\n",
    "                          batch_size=16,\n",
    "                          dim=(224, 224),\n",
    "                          n_channels=3,\n",
    "                          shuffle=True)\n",
    "\n",
    "val_gen = FBMMDataGenerator(data_dict=val_dict,\n",
    "                          tokenizer=tokenizer,\n",
    "                          pad_len=max_len,\n",
    "                          batch_size=16,\n",
    "                          dim=(224, 224),\n",
    "                          n_channels=3,\n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "219/532 [===========>..................] - ETA: 9:06 - loss: 0.6286 - accuracy: 0.6461"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "mcp_save = ModelCheckpoint(model_dir + 'best_roberta_fusion.h5', \n",
    "                           save_weights_only=True, \n",
    "                           save_best_only=True, \n",
    "                           verbose=1,\n",
    "                           monitor='val_loss', \n",
    "                           mode='min')\n",
    "\n",
    "history = fcm_model.fit_generator(train_gen,\n",
    "                    validation_data=val_gen,\n",
    "                    shuffle=True,\n",
    "                    epochs=5,\n",
    "                    callbacks=[mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label = 'acc')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label = 'loss')\n",
    "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fcm_model.load_weights(model_dir + 'best_roberta_fusion.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score\n",
    "import math\n",
    "\n",
    "y_val = val_gen.classes\n",
    "\n",
    "# get AUROC\n",
    "preds = fcm_model.predict_generator(val_gen)\n",
    "print('Val AUROC:', roc_auc_score(y_val, preds))\n",
    "\n",
    "# get loss and acc\n",
    "preds_bin = np.array(preds)\n",
    "preds_bin[preds>0.5] = 1\n",
    "preds_bin[preds<=0.5] = 0\n",
    "print('Val Accuracy:', accuracy_score(y_val, preds_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python36env",
   "language": "python",
   "name": "python36env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
