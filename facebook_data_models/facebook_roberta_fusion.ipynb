{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "import gc\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8500\n",
      "500\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# make image dataloader using flow_from_dataframe\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# load data to extract labels\n",
    "data_dir = '../facebook_challenge_data/'\n",
    "model_dir = 'models/'\n",
    "\n",
    "# load data and print sizes\n",
    "def get_dict(path):\n",
    "    jsonl_content = open(path, 'r').read()\n",
    "    data = [json.loads(jline) for jline in jsonl_content.split('\\n')]\n",
    "    return {datum['id'] : datum for datum in data}\n",
    "\n",
    "\n",
    "train_dict = get_dict(data_dir + 'train.jsonl')\n",
    "val_dict = get_dict(data_dir + 'dev.jsonl')\n",
    "test_dict = get_dict(data_dir + 'test.jsonl')\n",
    "\n",
    "print(len(train_dict))\n",
    "print(len(val_dict))\n",
    "print(len(test_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load pretrained roberta\n",
    "# from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, TFRobertaModel\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# class ROBERTA(transformers.TFRobertaModel):\n",
    "\n",
    "#     def __init__(self, config, *inputs, **kwargs):\n",
    "#         super(ROBERTA, self).__init__(config, *inputs, **kwargs)\n",
    "#         self.roberta.call = tf.function(self.roberta.call)\n",
    "# #         self.roberta.trainable = False # freeze pretrained roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load pretrained resnet\n",
    "# image_encoder = tf.keras.applications.ResNet152(include_top=False, \n",
    "#                                weights='imagenet', \n",
    "#                                input_shape=(299, 299, 3)\n",
    "# )\n",
    "\n",
    "# # load inception bc of memory constraints\n",
    "# # image_encoder = tf.keras.applications.InceptionV3(include_top=False, \n",
    "# #                                weights='imagenet', \n",
    "# #                                input_shape=(299, 299, 3)\n",
    "# # )\n",
    "\n",
    "# for layer in image_encoder.layers[:-1]: layer.trainable = False # freeze pretrained layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://keras.io/examples/nlp/text_extraction_with_bert/\n",
    "# # https://github.com/huggingface/transformers/issues/1350\n",
    "\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Input\n",
    "# from tensorflow.keras import layers\n",
    "\n",
    "# max_len = 50\n",
    "\n",
    "# # handle text\n",
    "# input_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
    "# roberta = ROBERTA.from_pretrained('roberta-base')\n",
    "# roberta_encodings = roberta([input_ids])[0]\n",
    "# text_embed = tf.squeeze(roberta_encodings[:, 0:1, :], axis=1) # Keep [CLS] token encoding\n",
    "# text_embed = layers.Dropout(0.1)(text_embed)\n",
    "# # text_embed = layers.Dense(512)(text_embed)\n",
    "\n",
    "\n",
    "# # handle image\n",
    "# # input_img = Input((224, 224, 3))\n",
    "# # img_embed = image_encoder(input_img)\n",
    "# # img_embed = layers.GlobalAveragePooling2D()(img_embed)\n",
    "# # img_embed = layers.Dense(1)(img_embed)\n",
    "\n",
    "# # concat\n",
    "# # pred = layers.Concatenate()([text_embed, img_embed])\n",
    "# pred = text_embed\n",
    "# # pred = layers.Dense(512, activation='relu')(pred)\n",
    "# # pred = layers.Dense(256, activation='relu')(pred)\n",
    "# pred = layers.Dense(1, activation='sigmoid')(pred)\n",
    "\n",
    "# model = Model(\n",
    "#     inputs=[input_ids],# , input_img],\n",
    "#     outputs=pred,\n",
    "# )\n",
    "\n",
    "# optimizer = tf.keras.optimizers.Adam(lr=5e-5)\n",
    "# model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "roberta (ROBERTA)            ((None, 50, 768), (None,  124645632 \n",
      "_________________________________________________________________\n",
      "tf_op_layer_strided_slice (T [(None, 1, 768)]          0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Squeeze (TensorF [(None, 768)]             0         \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "outputs (Dense)              (None, 1)                 769       \n",
      "=================================================================\n",
      "Total params: 124,646,401\n",
      "Trainable params: 124,646,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load pretrained roberta\n",
    "import transformers\n",
    "from tensorflow.keras import layers\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, TFRobertaModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "MAX_SEQ_LEN = 50\n",
    "\n",
    "class ROBERTA(transformers.TFRobertaModel):\n",
    "\n",
    "    def __init__(self, config, *inputs, **kwargs):\n",
    "        super(ROBERTA, self).__init__(config, *inputs, **kwargs)\n",
    "        self.roberta.call = tf.function(self.roberta.call)\n",
    "\n",
    "input_ids = layers.Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32)\n",
    "roberta = ROBERTA.from_pretrained('roberta-base')\n",
    "roberta_encodings = roberta([input_ids])[0]\n",
    "doc_encoding = tf.squeeze(roberta_encodings[:, 0:1, :], axis=1) # Keep [CLS] token encoding\n",
    "doc_encoding = layers.Dropout(0.1)(doc_encoding) # Apply dropout\n",
    "outputs = layers.Dense(1, activation='sigmoid', name='outputs')(doc_encoding)\n",
    "model = tf.keras.models.Model(inputs=[input_ids], outputs=[outputs])\n",
    "\n",
    "# compile\n",
    "optimizer = tf.keras.optimizers.Adam(lr=5e-5)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint # for random cropping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "class FBMMDataGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, data_dict, tokenizer, pad_len, batch_size=32, dim=(299, 299), n_channels=3, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.data_dict = data_dict\n",
    "        self.batch_size = batch_size\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.pad_len = pad_len\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        # build labels list and id list\n",
    "        self.id_list = list(self.data_dict.keys())\n",
    "        self.labels = {ID: self.data_dict[ID]['label'] for ID in self.id_list}\n",
    "        self.img_list = {ID: self.data_dict[ID]['img'] for ID in self.id_list}\n",
    "            \n",
    "        # get text dictionary\n",
    "        self.text_dict = self.process_text(self.id_list)\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "        self.classes = [self.labels[self.id_list[i]] for i in self.indexes]\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.id_list) / self.batch_size)) + 1 # last batch is partial\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:index*self.batch_size + self.batch_size]\n",
    "        \n",
    "        \n",
    "        # Find list of IDs\n",
    "        id_list_temp = [self.id_list[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X_txt, X_img, y = self.__data_generation(id_list_temp)\n",
    "        \n",
    "        return X_txt, y #(X_txt, X_img), y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.id_list))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, id_list_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X_img = np.empty((len(id_list_temp), *self.dim, self.n_channels))\n",
    "        X_txt = np.empty((len(id_list_temp), self.pad_len))\n",
    "        y = np.empty(len(id_list_temp), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(id_list_temp):\n",
    "            # Store sample\n",
    "            X_img[i,] = self.process_img(data_dir + self.img_list[ID])\n",
    "            X_txt[i,] = self.text_dict[ID]\n",
    "\n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X_txt.astype(int), X_img, y\n",
    "    \n",
    "    def process_img(self, path): # method for getting image\n",
    "        img = Image.open(path)\n",
    "        img.load()\n",
    "        scale_size = int(1.5 * self.dim[0]) # want cropping\n",
    "        if img.size[0] < img.size[1]: # width greater than height\n",
    "            wpercent = (scale_size/float(img.size[0]))\n",
    "            hsize = int((float(img.size[1])*float(wpercent)))\n",
    "            img = img.resize((scale_size,hsize), Image.ANTIALIAS)\n",
    "        else: # height greater than width\n",
    "            hpercent = (scale_size/float(img.size[1]))\n",
    "            wsize = int((float(img.size[0])*float(hpercent)))\n",
    "            img = img.resize((wsize, scale_size), Image.ANTIALIAS)\n",
    "            \n",
    "        data = np.asarray(img, dtype='uint8')\n",
    "        im = self.augment(data) # apply transformation\n",
    "        \n",
    "        \n",
    "        if im.shape==(self.dim[0], self.dim[1]): im = np.stack((im,)*3, axis=-1) # handle grayscale\n",
    "        if im.shape == (*self.dim, 4): im = im[:,:,:3] # handle weird case\n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def augment(self, im): # random crop and random mirror\n",
    "        \n",
    "        # random crop\n",
    "        x_max, y_max = im.shape[0], im.shape[1]\n",
    "        x_start, y_start = randint(0, x_max - self.dim[0]), randint(0, y_max - self.dim[1])\n",
    "        im = im[x_start:x_start + self.dim[0], y_start:y_start + self.dim[1]]\n",
    "        \n",
    "        # random mirror\n",
    "        if randint(0,1): im = np.flip(im, axis=1)\n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def process_text(self, id_list):\n",
    "        \n",
    "        # matrix for texts\n",
    "        texts = [self.data_dict[ID]['text'] for ID in id_list]\n",
    "        sequences = [self.tokenizer.encode(text) for text in texts] # make this more efficient...\n",
    "        text_seqs = pad_sequences(sequences, maxlen=self.pad_len)\n",
    "        \n",
    "        id_to_seq = {ID: txt for (ID, txt) in zip(id_list, text_seqs)} # map id to text seq\n",
    "        \n",
    "        return id_to_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test tokenizer\n",
    "\n",
    "# print(type(tokenizer))\n",
    "# print(tokenizer.encode('hi my name is bob and i like to go swimming'))\n",
    "# print(tokenizer.encode(['hi my name is bob and i like to go swimming', 'hello']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data generators\n",
    "\n",
    "# create data generators\n",
    "max_len = 50\n",
    "train_gen = FBMMDataGenerator(data_dict=train_dict,\n",
    "                          tokenizer=tokenizer,\n",
    "                          pad_len=max_len,\n",
    "                          batch_size=16,\n",
    "                          dim=(224, 224),\n",
    "                          n_channels=3,\n",
    "                          shuffle=True)\n",
    "\n",
    "val_gen = FBMMDataGenerator(data_dict=val_dict,\n",
    "                          tokenizer=tokenizer,\n",
    "                          pad_len=max_len,\n",
    "                          batch_size=16,\n",
    "                          dim=(224, 224),\n",
    "                          n_channels=3,\n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "531/532 [============================>.] - ETA: 0s - loss: 0.6665 - accuracy: 0.6357\n",
      "Epoch 00001: val_loss improved from inf to 0.73164, saving model to models/best_roberta_fusion.h5\n",
      "532/532 [==============================] - 382s 718ms/step - loss: 0.6665 - accuracy: 0.6358 - val_loss: 0.7316 - val_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "113/532 [=====>........................] - ETA: 4:30 - loss: 0.6545 - accuracy: 0.6460"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "mcp_save = ModelCheckpoint(model_dir + 'best_roberta_fusion.h5', \n",
    "                           save_weights_only=True, \n",
    "                           save_best_only=True, \n",
    "                           verbose=1,\n",
    "                           monitor='val_loss', \n",
    "                           mode='min')\n",
    "\n",
    "history = model.fit_generator(train_gen,\n",
    "                    validation_data=val_gen,\n",
    "                    shuffle=True,\n",
    "                    epochs=5,\n",
    "                    callbacks=[mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(model_dir + 'best_roberta_fusion.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score\n",
    "import math\n",
    "\n",
    "y_val = val_gen.classes\n",
    "\n",
    "# get AUROC\n",
    "preds = model.predict_generator(val_gen)\n",
    "print('Val AUROC:', roc_auc_score(y_val, preds))\n",
    "\n",
    "# get loss and acc\n",
    "preds_bin = np.array(preds)\n",
    "preds_bin[preds>0.5] = 1\n",
    "preds_bin[preds<=0.5] = 0\n",
    "print('Val Accuracy:', accuracy_score(y_val, preds_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, y = train_gen.__getitem__(0)\n",
    "\n",
    "print([tokenizer.decode(t) for t in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python36env",
   "language": "python",
   "name": "python36env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
