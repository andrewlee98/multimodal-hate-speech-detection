{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import cv2\n",
    "import re\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8500\n",
      "500\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# make image dataloader using flow_from_dataframe\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# load data to extract labels\n",
    "data_dir = '../facebook_challenge_data/'\n",
    "model_dir = 'models/'\n",
    "\n",
    "# load data and print sizes\n",
    "def get_dict(path):\n",
    "    jsonl_content = open(path, 'r').read()\n",
    "    data = [json.loads(jline) for jline in jsonl_content.split('\\n')]\n",
    "    return {datum['id'] : datum for datum in data}\n",
    "\n",
    "\n",
    "train_dict = get_dict(data_dir + 'train.jsonl')\n",
    "val_dict = get_dict(data_dir + 'dev.jsonl')\n",
    "test_dict = get_dict(data_dir + 'test.jsonl')\n",
    "\n",
    "print(len(train_dict))\n",
    "print(len(val_dict))\n",
    "print(len(test_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 50, 100)           1264500   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 150)               150600    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 1,415,251\n",
      "Trainable params: 150,751\n",
      "Non-trainable params: 1,264,500\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 8, 8, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               67109376  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 88,912,673\n",
      "Trainable params: 88,878,241\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# load pretrained LSTM and CNN for text and images\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "lstm = load_model(model_dir + 'fb_lstm.h5')\n",
    "cnn = load_model(model_dir + 'best_fb_inc_cnn.h5')\n",
    "\n",
    "print(lstm.summary())\n",
    "print(cnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 50, 100)           1264500   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 150)               150600    \n",
      "=================================================================\n",
      "Total params: 1,415,100\n",
      "Trainable params: 150,600\n",
      "Non-trainable params: 1,264,500\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 8, 8, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               67109376  \n",
      "=================================================================\n",
      "Total params: 88,912,160\n",
      "Trainable params: 88,877,728\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "280952"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new models that are all but the last layer\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "text_net = Sequential()\n",
    "for layer in lstm.layers[:-1]: text_net.add(layer)\n",
    "print(text_net.summary())\n",
    "\n",
    "img_net = Sequential()\n",
    "for layer in cnn.layers[:-1]: img_net.add(layer)\n",
    "print(img_net.summary())\n",
    "\n",
    "# free up memory from old models:\n",
    "del lstm\n",
    "del cnn\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = pickle.load(open(model_dir + 'fb_tokenizer.pkl', 'rb'))\n",
    "pad_len = text_net.layers[0].input_shape[-1]\n",
    "\n",
    "# build same embedding matrix as in the lstm file\n",
    "from tensorflow.keras.layers import Dense, Input, Embedding, Conv1D\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "word_index = word_index = tokenizer.word_index\n",
    "MAX_SEQ_LEN = pad_len\n",
    "\n",
    "# map word to embedding\n",
    "embeddings_index = {}\n",
    "for line in open(os.path.join('..', 'glove.twitter.27B.100d.txt')):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    embeddings_index[word] = np.asarray(values[1:], dtype='float32')\n",
    "\n",
    "# create embedding matrix (words without embeddings get zero embeddings)\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "\n",
    "token_embedding = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQ_LEN,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 256) (None, 47, 256)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 100)      1264500     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 512)          88912160    input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 50, 256)      25856       embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 256)          131328      sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 47, 256)      262400      dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         (None, None, 256)    0           dense_9[0][0]                    \n",
      "                                                                 conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 256)          0           attention_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 256)          65536       global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 256)          65792       dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 256)          65536       global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 256)          65792       dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 256)          65536       global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 256)          65792       dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 256)          0           dense_10[0][0]                   \n",
      "                                                                 dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 256)          0           dense_12[0][0]                   \n",
      "                                                                 dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 256)          0           dense_14[0][0]                   \n",
      "                                                                 dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256)          0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 256)          0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 256)          0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 256)          0           activation_3[0][0]               \n",
      "                                                                 global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 256)          0           activation_4[0][0]               \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 150)          1415100     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 256)          0           multiply[0][0]                   \n",
      "                                                                 multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 918)          0           sequential[2][0]                 \n",
      "                                                                 sequential_1[2][0]               \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 2048)         1882112     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1024)         2098176     dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 512)          524800      dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 1)            513         dense_18[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 96,910,929\n",
      "Trainable params: 94,347,497\n",
      "Non-trainable params: 2,563,432\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# build attention model with image vector as query\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Attention\n",
    "from tensorflow.keras.layers import concatenate, Attention, Reshape, Dense, Input, Embedding, Conv1D, Add, Activation, Multiply\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import activations\n",
    "\n",
    "attention_dim = 256 # 256 in fb paper\n",
    "\n",
    "#inputs\n",
    "text_input = Input((text_net.layers[0].input_shape[-1],)) # get rid of None's in front, context/value\n",
    "img_input = Input((img_net.layers[0].input_shape[1:])) # get rid of None's in front, query\n",
    "\n",
    "# FCM embeddings\n",
    "text_embed = text_net(text_input)\n",
    "\n",
    "# get [batch_size, Tq, dim] embeddings from text\n",
    "txt_value_embeddings = token_embedding(text_input)\n",
    "transformed_txt_value_embeddings = Dense(attention_dim)(txt_value_embeddings) # get more dimensions from text\n",
    "cnn_layer = Conv1D(filters=attention_dim, kernel_size=4) # 1D conv for getting seq from txt\n",
    "t_prime = cnn_layer(transformed_txt_value_embeddings)\n",
    "\n",
    "# get [batch_size, Tv, dim] embeddings from image\n",
    "img_embed = img_net(img_input) # this is the query\n",
    "g_prime = Dense(attention_dim)(img_embed) # linear activation to get same dimension\n",
    "\n",
    "print(g_prime.shape, t_prime.shape)\n",
    "# do attention input to DNN as in link\n",
    "a = tf.keras.layers.Attention()([g_prime, t_prime])\n",
    "a = tf.keras.layers.GlobalAveragePooling1D()(a)\n",
    "\n",
    "# symmetric-gated fusion\n",
    "gate_dim = 256\n",
    "\n",
    "beta_a = Add()([Dense(gate_dim, use_bias=False)(a), Dense(gate_dim)(g_prime)]) \n",
    "beta_a = Activation(activations.relu)(beta_a) # sigma(W_a * a + U_a * g' + b_a)\n",
    "\n",
    "beta_g = Add()([Dense(gate_dim, use_bias=False)(a), Dense(gate_dim)(g_prime)]) \n",
    "beta_g = Activation(activations.relu)(beta_g) # sigma(W_g * a + U_g * g' + b_g)\n",
    "\n",
    "m = Add()([Dense(gate_dim, use_bias=False)(a), Dense(gate_dim)(g_prime)]) # sigma(W_m * a + U_m * g' + b_m)\n",
    "m = Activation(activations.tanh)(m)\n",
    "\n",
    "f = Add()([Multiply()([beta_a, a]), Multiply()([beta_g, m])])\n",
    "\n",
    "# concatenate it all together\n",
    "input_layer = tf.keras.layers.Concatenate()([text_embed, img_embed, f])\n",
    "\n",
    "x = Dense(2048, activation='relu')(input_layer)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "prediction = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=[text_input, img_input], outputs=prediction)\n",
    "print(model.summary())\n",
    "\n",
    "optimizer = Adam(lr = 1e-6)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint # for random cropping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "class FBMMDataGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, data_dict, tokenizer, pad_len, batch_size=32, dim=(299, 299), n_channels=3, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.data_dict = data_dict\n",
    "        self.batch_size = batch_size\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.pad_len = pad_len\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        # build labels list and id list\n",
    "        self.id_list = list(self.data_dict.keys())\n",
    "        self.labels = {ID: self.data_dict[ID]['label'] for ID in self.id_list}\n",
    "        self.img_list = {ID: self.data_dict[ID]['img'] for ID in self.id_list}\n",
    "            \n",
    "        # get text dictionary\n",
    "        self.text_dict = self.process_text(self.id_list)\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "        self.classes = [self.labels[self.id_list[i]] for i in self.indexes]\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.id_list) / self.batch_size)) + 1 # last batch is partial\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:index*self.batch_size + self.batch_size]\n",
    "        \n",
    "        \n",
    "        # Find list of IDs\n",
    "        id_list_temp = [self.id_list[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X_txt, X_img, y = self.__data_generation(id_list_temp)\n",
    "        \n",
    "        return (X_txt, X_img), y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.id_list))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, id_list_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X_img = np.empty((len(id_list_temp), *self.dim, self.n_channels))\n",
    "        X_txt = np.empty((len(id_list_temp), self.pad_len))\n",
    "        y = np.empty(len(id_list_temp), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(id_list_temp):\n",
    "            # Store sample\n",
    "            X_img[i,] = self.process_img(data_dir + self.img_list[ID])\n",
    "            X_txt[i,] = self.text_dict[ID]\n",
    "\n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X_txt, X_img, y\n",
    "    \n",
    "    def process_img(self, path): # method for getting image\n",
    "        img = Image.open(path)\n",
    "        img.load()\n",
    "        img = img.resize(self.dim, Image.ANTIALIAS)\n",
    "        data = np.asarray(img, dtype='uint8')\n",
    "        im = self.augment(data)\n",
    "        \n",
    "        \n",
    "        if im.shape==(self.dim[0], self.dim[1]): im = np.stack((im,)*3, axis=-1) # handle grayscale\n",
    "        if im.shape == (*self.dim, 4): im = im[:,:,:3] # handle weird case\n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def augment(self, im): # random crop and random mirror\n",
    "        \n",
    "        # random crop\n",
    "        x_max, y_max = im.shape[0], im.shape[1]\n",
    "        x_start, y_start = randint(0, x_max - self.dim[0]), randint(0, y_max - self.dim[1])\n",
    "        im = im[x_start:x_start + self.dim[0], y_start:y_start + self.dim[1]]\n",
    "        \n",
    "        # random mirror\n",
    "        if randint(0,1): im = np.flip(im, axis=1)\n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def process_text(self, id_list):\n",
    "        \n",
    "        # matrix for texts\n",
    "        texts = [self.data_dict[ID]['text'] for ID in id_list]\n",
    "        sequences = self.tokenizer.texts_to_sequences(texts)\n",
    "        text_seqs = pad_sequences(sequences, maxlen=self.pad_len)\n",
    "        \n",
    "        id_to_seq = dict() # map id to text sequence compatible with embedding layer\n",
    "        for ID, txt in zip(id_list, text_seqs):\n",
    "            id_to_seq[ID] = txt\n",
    "        \n",
    "        return id_to_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data generators\n",
    "tokenizer = pickle.load(open(model_dir + 'fb_tokenizer.pkl', 'rb'))\n",
    "pad_len = text_net.layers[0].input_shape[-1]\n",
    "\n",
    "# create data generators\n",
    "train_gen = FBMMDataGenerator(data_dict=train_dict,\n",
    "                          tokenizer=tokenizer,\n",
    "                          pad_len=pad_len,\n",
    "                          batch_size=32,\n",
    "                          dim=(299, 299),\n",
    "                          n_channels=3,\n",
    "                          shuffle=True)\n",
    "\n",
    "val_gen = FBMMDataGenerator(data_dict=val_dict,\n",
    "                          tokenizer=tokenizer,\n",
    "                          pad_len=pad_len,\n",
    "                          batch_size=32,\n",
    "                          dim=(299, 299),\n",
    "                          n_channels=3,\n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "266/266 [==============================] - 466s 2s/step - loss: 0.6392 - accuracy: 0.6409 - val_loss: 0.7371 - val_accuracy: 0.5020\n",
      "Epoch 2/10\n",
      "266/266 [==============================] - 451s 2s/step - loss: 0.5905 - accuracy: 0.6891 - val_loss: 0.7610 - val_accuracy: 0.5100\n",
      "Epoch 3/10\n",
      "266/266 [==============================] - 452s 2s/step - loss: 0.5512 - accuracy: 0.7333 - val_loss: 0.8106 - val_accuracy: 0.5080\n",
      "Epoch 4/10\n",
      "266/266 [==============================] - 453s 2s/step - loss: 0.5150 - accuracy: 0.7587 - val_loss: 0.7690 - val_accuracy: 0.5340\n",
      "Epoch 5/10\n",
      "266/266 [==============================] - 452s 2s/step - loss: 0.4839 - accuracy: 0.7784 - val_loss: 0.8062 - val_accuracy: 0.5240\n",
      "Epoch 6/10\n",
      "266/266 [==============================] - 453s 2s/step - loss: 0.4517 - accuracy: 0.7986 - val_loss: 0.8082 - val_accuracy: 0.5400\n",
      "Epoch 7/10\n",
      "266/266 [==============================] - 454s 2s/step - loss: 0.4186 - accuracy: 0.8209 - val_loss: 0.8375 - val_accuracy: 0.5440\n",
      "Epoch 8/10\n",
      "266/266 [==============================] - 453s 2s/step - loss: 0.3898 - accuracy: 0.8347 - val_loss: 0.8733 - val_accuracy: 0.5300\n",
      "Epoch 9/10\n",
      "266/266 [==============================] - 454s 2s/step - loss: 0.3583 - accuracy: 0.8522 - val_loss: 0.9842 - val_accuracy: 0.5280\n",
      "Epoch 10/10\n",
      "266/266 [==============================] - 453s 2s/step - loss: 0.3203 - accuracy: 0.8732 - val_loss: 0.9710 - val_accuracy: 0.5520\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "mcp_save = ModelCheckpoint(model_dir + 'best_sym_gated_fb_weights.h5', \n",
    "                           save_weights_only=True, \n",
    "                           save_best_only=True, \n",
    "                           monitor='val_loss', \n",
    "                           mode='min')\n",
    "\n",
    "history = model.fit_generator(train_gen,\n",
    "                    validation_data=val_gen,\n",
    "                    shuffle=True,\n",
    "                    epochs=10,\n",
    "                    callbacks=[mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the weights from the best model\n",
    "model.load_weights(model_dir + 'best_sym_gated_fb_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val AUROC: 0.436\n",
      "Val Accuracy: 0.498\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score\n",
    "import math\n",
    "\n",
    "y_val = val_gen.classes\n",
    "\n",
    "# get AUROC\n",
    "preds = model.predict_generator(val_gen)\n",
    "print('Val AUROC:', roc_auc_score(y_val, preds))\n",
    "\n",
    "# get loss and acc\n",
    "preds_bin = np.array(preds)\n",
    "preds_bin[preds>0.5] = 1\n",
    "preds_bin[preds<=0.5] = 0\n",
    "print('Val Accuracy:', accuracy_score(y_val, preds_bin))\n",
    "\n",
    "# get F1\n",
    "# print('Val F1:', f1_score(y_val, preds_bin, zero_division=1))\n",
    "# print('Val Precision:', precision_score(y_val, preds_bin, zero_division=1))\n",
    "# print('Val Recall:', recall_score(y_val, preds_bin, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test the data generator\n",
    "imgs, texts, ys = train_gen.__getitem__(0)\n",
    "ids = train_gen.id_list[:32]\n",
    "\n",
    "for ID, text, img, y in list(zip(ids, texts, imgs, ys))[:3]:\n",
    "    print(ID)\n",
    "    print(text)\n",
    "    img = Image.fromarray(np.uint8(img), 'RGB')\n",
    "    display(img)\n",
    "    print('label:', y, '\\n\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
