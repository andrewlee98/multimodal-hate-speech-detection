{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import cv2\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Tweet Dictionary: 149823\n",
      "Number of Images: 150000\n",
      "Number of Image Texts: 59252\n"
     ]
    }
   ],
   "source": [
    "# create giant dictionary for all data\n",
    "data_dir = 'mmhs150k/'\n",
    "\n",
    "# load data and print sizes\n",
    "tweet_dict = json.load(open(data_dir + 'MMHS150K_GT.json', 'r'))\n",
    "print('Length of Tweet Dictionary:', len(tweet_dict))\n",
    "print('Number of Images:', len(os.listdir(data_dir + 'img_resized')))\n",
    "print('Number of Image Texts:', len(os.listdir(data_dir + 'img_txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<user> <user> nigga <allcaps>   <repeat>  did <allcaps>  you <allcaps>  not <allcaps>  hear <allcaps>  the <allcaps>  chris <allcaps>  brown <allcaps>  song <allcaps> ! <repeat> <url>\n",
      "<smile> <smile> <smile> <hashtag>  hello world <hashtag> helloworld <hashtag>  hello\n"
     ]
    }
   ],
   "source": [
    "# method for cleaning text like in https://nlp.stanford.edu/projects/glove/preprocess-twitter.rb\n",
    "def hashtag(text):\n",
    "    hashtag_body = text.group()[1:]\n",
    "    if hashtag_body.isupper(): return \"<hashtag> {} \".format(hashtag_body.lower())\n",
    "    else: return ' '.join([\"<hashtag>\"] + [re.sub(r\"([A-Z])\",r\" \\1\", hashtag_body, flags=re.MULTILINE | re.DOTALL)])\n",
    "\n",
    "def allcaps(text): return text.group().lower() + ' <allcaps> '    \n",
    "\n",
    "def clean_tweet_text(t):\n",
    "    eyes = r'[8:=;]'\n",
    "    nose = r\"['`\\-]?\"\n",
    "    \n",
    "    t = re.sub(r'https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*', '<url>', t)\n",
    "    t = re.sub(r'@\\w+', '<user>', t)\n",
    "    t = re.sub(r'{}{}[)dD]+|[)dD]+{}{}'.format(eyes, nose, nose, eyes), '<smile>', t)\n",
    "    t = re.sub(r'{}{}p+\".format(eyes, nose)', '<lolface>', t)\n",
    "    t = re.sub(r'{}{}\\(+|\\)+{}{}'.format(eyes, nose, nose, eyes), '<sadface>', t)\n",
    "    t = re.sub(r'{}{}[\\/|l*]'.format(eyes, nose), '<neutralface>', t)\n",
    "    t = re.sub(r'/', ' / ', t)\n",
    "    t = re.sub(r'<3','<heart>', t)\n",
    "    t = re.sub(r'[-+]?[.\\d]*[\\d]+[:,.\\d]*', '<number>', t)\n",
    "    t = re.sub(r'#\\S+', hashtag, t)\n",
    "    t = re.sub(r'([!?.]){2,}', r'\\1 <repeat>', t)\n",
    "    t = re.sub(r'\\b(\\S*?)(.)\\2{2,}\\b', r'\\1\\2 <elong>', t)\n",
    "    t = re.sub(r'([A-Z]){2,}', allcaps, t)\n",
    "    t = re.sub(r'{}'.format(r'[\\\".,-;&:]'), ' ', t)\n",
    "    return t.lower()\n",
    "    \n",
    "print(clean_tweet_text('@SLAAATTTTT @AINTSHlTLAUGHS NIGGA...  DID YOU NOT HEAR THE CHRIS BROWN SONG?!?!?! https://t.co/1hwQMRczOw'))\n",
    "print(clean_tweet_text(':) :-) 8) #HelloWorld #helloworld #Hello'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data len: 134823\n",
      "Val data len: 5000\n",
      "Longest training sequence length: 55\n"
     ]
    }
   ],
   "source": [
    "# initialize data dictionary {id: (tweet text, label)}\n",
    "train_data = []\n",
    "word_index = dict() # dictionary mapping word to index\n",
    "\n",
    "def get_data_list(path):\n",
    "    data = []\n",
    "    for id in open(data_dir + path, 'r').read().splitlines():\n",
    "\n",
    "        # process text (tweet special tokens)\n",
    "        text = tweet_dict[id]['tweet_text']\n",
    "        text = clean_tweet_text(text)\n",
    "        for word in text.split():\n",
    "            if word not in word_index: word_index[word] = len(word_index)\n",
    "\n",
    "        # get majority vote label\n",
    "        binary_labels = [1 if n > 0 else 0 for n in tweet_dict[id]['labels']]\n",
    "        label = 1 if sum(binary_labels)/len(tweet_dict[id]['labels']) > 0.5 else 0\n",
    "\n",
    "        # save to list\n",
    "        data.append((text, label))\n",
    "\n",
    "    return data\n",
    "    \n",
    "train_data = get_data_list('splits/train_ids.txt')\n",
    "val_data = get_data_list('splits/val_ids.txt')\n",
    "print('Train data len:', len(train_data))\n",
    "print('Val data len:', len(val_data))\n",
    "\n",
    "# print longest training sequence length\n",
    "texts2, _ = zip(*train_data)\n",
    "print('Longest training sequence length:', max([len(t.split()) for t in texts2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64960 unique tokens.\n",
      "Shape of data tensor: (134823, 60)\n",
      "Shape of label tensor: (134823,)\n"
     ]
    }
   ],
   "source": [
    "# make the dataset\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "MAX_NUMBER_OF_WORDS = 100\n",
    "MAX_SEQ_LEN = 60\n",
    "\n",
    "# training\n",
    "texts, labels = zip(*train_data)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NUMBER_OF_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "x_train = pad_sequences(sequences, maxlen=MAX_SEQ_LEN)\n",
    "\n",
    "y_train = np.asarray(labels)\n",
    "print('Shape of data tensor:', x_train.shape)\n",
    "print('Shape of label tensor:', y_train.shape)\n",
    "\n",
    "# validation\n",
    "val_texts, val_labels = zip(*val_data)\n",
    "\n",
    "val_sequences = tokenizer.texts_to_sequences(val_texts) # apply train tokenizer\n",
    "x_val = pad_sequences(val_sequences, maxlen=MAX_SEQ_LEN)\n",
    "y_val = np.asarray(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding layer\n",
    "from keras.layers import Embedding\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "# map word to embedding\n",
    "embeddings_index = {}\n",
    "for line in open(os.path.join('glove', 'glove.twitter.27B.100d.txt')):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    embeddings_index[word] = np.asarray(values[1:], dtype='float32')\n",
    "\n",
    "# create embedding matrix (words without embeddings get zero embeddings)\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQ_LEN,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 60, 100)           6496100   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 150)               15150     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 6,591,801\n",
      "Trainable params: 95,701\n",
      "Non-trainable params: 6,496,100\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 107858 samples, validate on 26965 samples\n",
      "Epoch 1/3\n",
      "107858/107858 [==============================] - 84s 775us/step - loss: 0.4748 - accuracy: 0.7886 - val_loss: 0.4639 - val_accuracy: 0.7944\n",
      "Epoch 2/3\n",
      "107858/107858 [==============================] - 81s 747us/step - loss: 0.4665 - accuracy: 0.7938 - val_loss: 0.4630 - val_accuracy: 0.7948\n",
      "Epoch 3/3\n",
      "107858/107858 [==============================] - 81s 750us/step - loss: 0.4651 - accuracy: 0.7944 - val_loss: 0.4636 - val_accuracy: 0.7946\n"
     ]
    }
   ],
   "source": [
    "# validation on subset of training set\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(150, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "# shuffle data\n",
    "indices = (np.arange(x_train.shape[0]))\n",
    "np.random.shuffle(indices)\n",
    "x_train, y_train = x_train[indices], y_train[indices]\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=3, batch_size=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 60, 100)           6496100   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 150)               15150     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 6,591,801\n",
      "Trainable params: 95,701\n",
      "Non-trainable params: 6,496,100\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 134823 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "134823/134823 [==============================] - 88s 653us/step - loss: 0.4729 - accuracy: 0.7901 - val_loss: 0.7591 - val_accuracy: 0.5840\n",
      "Epoch 2/10\n",
      "134823/134823 [==============================] - 88s 653us/step - loss: 0.4660 - accuracy: 0.7936 - val_loss: 0.7524 - val_accuracy: 0.5984\n",
      "Epoch 3/10\n",
      "134823/134823 [==============================] - 88s 653us/step - loss: 0.4645 - accuracy: 0.7940 - val_loss: 0.7992 - val_accuracy: 0.5794\n",
      "Epoch 4/10\n",
      "134823/134823 [==============================] - 88s 654us/step - loss: 0.4633 - accuracy: 0.7946 - val_loss: 0.7599 - val_accuracy: 0.5866\n",
      "Epoch 5/10\n",
      "134823/134823 [==============================] - 88s 653us/step - loss: 0.4622 - accuracy: 0.7954 - val_loss: 0.7530 - val_accuracy: 0.6108\n",
      "Epoch 6/10\n",
      "134823/134823 [==============================] - 87s 648us/step - loss: 0.4610 - accuracy: 0.7962 - val_loss: 0.7813 - val_accuracy: 0.5950\n",
      "Epoch 7/10\n",
      "134823/134823 [==============================] - 88s 654us/step - loss: 0.4595 - accuracy: 0.7969 - val_loss: 0.7657 - val_accuracy: 0.5914\n",
      "Epoch 8/10\n",
      "134823/134823 [==============================] - 88s 656us/step - loss: 0.4575 - accuracy: 0.7977 - val_loss: 0.7586 - val_accuracy: 0.6102\n",
      "Epoch 9/10\n",
      "134823/134823 [==============================] - 91s 674us/step - loss: 0.4548 - accuracy: 0.7994 - val_loss: 0.7530 - val_accuracy: 0.5934\n",
      "Epoch 10/10\n",
      "134823/134823 [==============================] - 88s 652us/step - loss: 0.4511 - accuracy: 0.8018 - val_loss: 0.8004 - val_accuracy: 0.5906\n"
     ]
    }
   ],
   "source": [
    "# validation on validation set\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(150, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=100, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb1343383c8>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
