{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import cv2\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Tweet Dictionary: 149823\n",
      "Number of Images: 150000\n",
      "Number of Image Texts: 59252\n"
     ]
    }
   ],
   "source": [
    "# create giant dictionary for all data\n",
    "data_dir = 'mmhs150k/'\n",
    "model_dir = 'models/'\n",
    "\n",
    "# load data and print sizes\n",
    "tweet_dict = json.load(open(data_dir + 'MMHS150K_GT.json', 'r'))\n",
    "print('Length of Tweet Dictionary:', len(tweet_dict))\n",
    "print('Number of Images:', len(os.listdir(data_dir + 'img_resized')))\n",
    "print('Number of Image Texts:', len(os.listdir(data_dir + 'img_txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<user> <user> nigga <allcaps>   <repeat>  did <allcaps>  you <allcaps>  not <allcaps>  hear <allcaps>  the <allcaps>  chris <allcaps>  brown <allcaps>  song <allcaps> ! <repeat> <url>\n",
      "<smile> <smile> <smile> <hashtag>  hello world <hashtag> helloworld <hashtag>  hello\n"
     ]
    }
   ],
   "source": [
    "# method for cleaning text like in https://nlp.stanford.edu/projects/glove/preprocess-twitter.rb\n",
    "def hashtag(text):\n",
    "    hashtag_body = text.group()[1:]\n",
    "    if hashtag_body.isupper(): return \"<hashtag> {} \".format(hashtag_body.lower())\n",
    "    else: return ' '.join([\"<hashtag>\"] + [re.sub(r\"([A-Z])\",r\" \\1\", hashtag_body, flags=re.MULTILINE | re.DOTALL)])\n",
    "\n",
    "def allcaps(text): return text.group().lower() + ' <allcaps> '    \n",
    "\n",
    "def clean_tweet_text(t):\n",
    "    eyes = r'[8:=;]'\n",
    "    nose = r\"['`\\-]?\"\n",
    "    \n",
    "    t = re.sub(r'https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*', '<url>', t)\n",
    "    t = re.sub(r'@\\w+', '<user>', t)\n",
    "    t = re.sub(r'{}{}[)dD]+|[)dD]+{}{}'.format(eyes, nose, nose, eyes), '<smile>', t)\n",
    "    t = re.sub(r'{}{}p+\".format(eyes, nose)', '<lolface>', t)\n",
    "    t = re.sub(r'{}{}\\(+|\\)+{}{}'.format(eyes, nose, nose, eyes), '<sadface>', t)\n",
    "    t = re.sub(r'{}{}[\\/|l*]'.format(eyes, nose), '<neutralface>', t)\n",
    "    t = re.sub(r'/', ' / ', t)\n",
    "    t = re.sub(r'<3','<heart>', t)\n",
    "    t = re.sub(r'[-+]?[.\\d]*[\\d]+[:,.\\d]*', '<number>', t)\n",
    "    t = re.sub(r'#\\S+', hashtag, t)\n",
    "    t = re.sub(r'([!?.]){2,}', r'\\1 <repeat>', t)\n",
    "    t = re.sub(r'\\b(\\S*?)(.)\\2{2,}\\b', r'\\1\\2 <elong>', t)\n",
    "    t = re.sub(r'([A-Z]){2,}', allcaps, t)\n",
    "    t = re.sub(r'{}'.format(r'[\\\".,-;&:]'), ' ', t)\n",
    "    return t.lower()\n",
    "    \n",
    "print(clean_tweet_text('@SLAAATTTTT @AINTSHlTLAUGHS NIGGA...  DID YOU NOT HEAR THE CHRIS BROWN SONG?!?!?! https://t.co/1hwQMRczOw'))\n",
    "print(clean_tweet_text(':) :-) 8) #HelloWorld #helloworld #Hello'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data len: 134823\n",
      "Val data len: 5000\n",
      "Test data len: 10000\n"
     ]
    }
   ],
   "source": [
    "# initialize data dictionary {id: (tweet text, label)}\n",
    "word_index = dict() # dictionary mapping word to index\n",
    "\n",
    "def get_data_list(path):\n",
    "    data = []\n",
    "    for id in open(data_dir + path, 'r').read().splitlines():\n",
    "\n",
    "        # process text (tweet special tokens)\n",
    "        text = tweet_dict[id]['tweet_text']\n",
    "        text = clean_tweet_text(text)\n",
    "        for word in text.split():\n",
    "            if word not in word_index: word_index[word] = len(word_index)\n",
    "\n",
    "        # get majority vote label\n",
    "        binary_labels = [1 if n > 0 else 0 for n in tweet_dict[id]['labels']]\n",
    "        label = 1 if sum(binary_labels)/len(tweet_dict[id]['labels']) > 0.5 else 0\n",
    "\n",
    "        # save to list\n",
    "        data.append((text, label))\n",
    "\n",
    "    return data\n",
    "    \n",
    "train_data = get_data_list('splits/train_ids.txt')\n",
    "val_data = get_data_list('splits/val_ids.txt')\n",
    "test_data = get_data_list('splits/test_ids.txt')\n",
    "print('Train data len:', len(train_data))\n",
    "print('Val data len:', len(val_data))\n",
    "print('Test data len:', len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest training sequence length: 55\n",
      "Found 75650 unique tokens.\n",
      "Shape of data tensor: (134823, 50)\n",
      "Shape of label tensor: (134823,)\n"
     ]
    }
   ],
   "source": [
    "# make the dataset\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "MAX_NUMBER_OF_WORDS = 20000\n",
    "MAX_SEQ_LEN = 50\n",
    "\n",
    "# training\n",
    "texts, labels = zip(*train_data)\n",
    "print('Longest training sequence length:', max([len(t.split()) for t in texts]))\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NUMBER_OF_WORDS, filters='\\t\\n', lower=True)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "x_train = pad_sequences(sequences, maxlen=MAX_SEQ_LEN)\n",
    "\n",
    "y_train = np.asarray(labels)\n",
    "print('Shape of data tensor:', x_train.shape)\n",
    "print('Shape of label tensor:', y_train.shape)\n",
    "\n",
    "# validation\n",
    "val_texts, val_labels = zip(*val_data)\n",
    "\n",
    "val_sequences = tokenizer.texts_to_sequences(val_texts) # apply train tokenizer\n",
    "x_val = pad_sequences(val_sequences, maxlen=MAX_SEQ_LEN)\n",
    "y_val = np.asarray(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thats  what u call a redneck lol <url> [539, 36, 59, 148, 5, 77, 129, 1]\n",
      "fuck my pussy chaturbate cut fingering happy tugs hot cunt tyra misoux switzerland   <url> [41, 12, 201, 19835, 529, 1009, 126, 267, 19, 13359, 1]\n"
     ]
    }
   ],
   "source": [
    "# testing that the sequences are being build correctly\n",
    "print(texts[0], sequences[0])\n",
    "print(val_texts[0], val_sequences[0])\n",
    "# print(tokenizer.get_config()['index_word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding layer\n",
    "from keras.layers import Embedding\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "# map word to embedding\n",
    "embeddings_index = {}\n",
    "for line in open(os.path.join('glove', 'glove.twitter.27B.100d.txt')):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    embeddings_index[word] = np.asarray(values[1:], dtype='float32')\n",
    "\n",
    "# create embedding matrix (words without embeddings get zero embeddings)\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQ_LEN,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 100)           7565100   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 150)               150600    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 7,715,851\n",
      "Trainable params: 150,751\n",
      "Non-trainable params: 7,565,100\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 107858 samples, validate on 26965 samples\n",
      "Epoch 1/3\n",
      "107858/107858 [==============================] - 91s 847us/step - loss: 0.4757 - accuracy: 0.7874 - val_loss: 0.4632 - val_accuracy: 0.7912\n",
      "Epoch 2/3\n",
      "107858/107858 [==============================] - 91s 842us/step - loss: 0.4636 - accuracy: 0.7935 - val_loss: 0.4615 - val_accuracy: 0.7918\n",
      "Epoch 3/3\n",
      "107858/107858 [==============================] - 91s 841us/step - loss: 0.4604 - accuracy: 0.7951 - val_loss: 0.4605 - val_accuracy: 0.7931\n"
     ]
    }
   ],
   "source": [
    "# validation on subset of training set\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(150))\n",
    "# model.add(Dense(150, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "# shuffle data\n",
    "indices = (np.arange(x_train.shape[0]))\n",
    "np.random.shuffle(indices)\n",
    "x_train, y_train = x_train[indices], y_train[indices]\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=3, batch_size=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 100)           7565100   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 150)               150600    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 150)               22650     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 7,738,501\n",
      "Trainable params: 173,401\n",
      "Non-trainable params: 7,565,100\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 134823 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "134823/134823 [==============================] - 109s 807us/step - loss: 0.4732 - accuracy: 0.7885 - val_loss: 0.7515 - val_accuracy: 0.5752\n",
      "Epoch 2/5\n",
      "134823/134823 [==============================] - 108s 800us/step - loss: 0.4625 - accuracy: 0.7935 - val_loss: 0.7806 - val_accuracy: 0.5694\n",
      "Epoch 3/5\n",
      "134823/134823 [==============================] - 107s 794us/step - loss: 0.4596 - accuracy: 0.7948 - val_loss: 0.7606 - val_accuracy: 0.5720\n",
      "Epoch 4/5\n",
      "134823/134823 [==============================] - 112s 830us/step - loss: 0.4565 - accuracy: 0.7965 - val_loss: 0.7642 - val_accuracy: 0.5810\n",
      "Epoch 5/5\n",
      "134823/134823 [==============================] - 113s 839us/step - loss: 0.4530 - accuracy: 0.7980 - val_loss: 0.7809 - val_accuracy: 0.5796\n"
     ]
    }
   ],
   "source": [
    "# validation on validation set\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(150, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=5, batch_size=100, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(history.history['val_accuracy'], label='val acc')\n",
    "plt.plot(history.history['accuracy'], label='train acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('accuracy over training epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUROC: 0.7324991999999999\n",
      "10000/10000 [==============================] - 11s 1ms/step\n",
      "Test acc: 0.5813999772071838\n",
      "Test F1: 0.33066837224176526\n",
      "Test Precision: 0.8245614035087719\n",
      "Test Recall: 0.2068\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "test_texts, test_labels = zip(*test_data)\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(test_texts) # apply train tokenizer\n",
    "x_test = pad_sequences(test_sequences, maxlen=MAX_SEQ_LEN)\n",
    "y_test = np.asarray(test_labels)\n",
    "\n",
    "# get AUROC\n",
    "preds = model.predict(x_test)\n",
    "print('Test AUROC:', roc_auc_score(y_test, preds))\n",
    "\n",
    "# get loss and acc\n",
    "print('Test acc:', model.evaluate(x_test, y_test)[1])\n",
    "\n",
    "# get F1\n",
    "preds_bin = model.predict_classes(x_test)\n",
    "print('Test F1:', f1_score(y_test, preds_bin, zero_division=1))\n",
    "print('Test Precision:', precision_score(y_test, preds_bin, zero_division=1))\n",
    "print('Test Recall:', recall_score(y_test, preds_bin, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.6771\n",
      "Test F1: 0.6761608665128874\n",
      "Test Precision: 0.6781331723999195\n",
      "Test Recall: 0.6742\n"
     ]
    }
   ],
   "source": [
    "# accuracy scores with different threshold\n",
    "\n",
    "preds_bin[preds>0.2] = 1\n",
    "preds_bin[preds<=0.2] = 0\n",
    "print('Test acc:', accuracy_score(y_test, preds_bin))\n",
    "print('Test F1:', f1_score(y_test, preds_bin, zero_division=1))\n",
    "print('Test Precision:', precision_score(y_test, preds_bin, zero_division=1))\n",
    "print('Test Recall:', recall_score(y_test, preds_bin, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_dir + 'lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
