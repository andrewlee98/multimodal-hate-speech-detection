{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create class for tweet training object\n",
    "class tweet:\n",
    "    def __init__(self, txt, labels):\n",
    "        self.txt = txt\n",
    "        self.img = None\n",
    "        self.img_txt = None\n",
    "        self.labels = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Tweet Dictionary: 149823\n",
      "Number of Images: 150000\n",
      "Number of Image Texts: 59252\n"
     ]
    }
   ],
   "source": [
    "# create giant dictionary for all data\n",
    "data_dir = 'mmhs150k/'\n",
    "pickle_dir = 'my_data/datasets/'\n",
    "\n",
    "# load data and print sizes\n",
    "tweet_dict = json.load(open(data_dir + 'MMHS150K_GT.json', 'r'))\n",
    "print('Length of Tweet Dictionary:', len(tweet_dict))\n",
    "print('Number of Images:', len(os.listdir(data_dir + 'img_resized')))\n",
    "print('Number of Image Texts:', len(os.listdir(data_dir + 'img_txt')))\n",
    "\n",
    "# initialize data dictionary\n",
    "data_dict = dict()\n",
    "for k, v in tweet_dict.items(): data_dict[k] = tweet(v['tweet_text'], v['labels_str'])\n",
    "\n",
    "# add img txt to dictionary\n",
    "for filename in tqdm(os.listdir(data_dir + 'img_txt')):\n",
    "    key = filename.split('.')[0]\n",
    "    data_dict[key].img_txt = json.load(open(data_dir + 'img_txt/' + filename, 'r'))['img_text']\n",
    "\n",
    "# add img to dictionary\n",
    "missing_keys = []\n",
    "for filename in tqdm(os.listdir(data_dir + 'img_resized')):\n",
    "    key = filename.split('.')[0]\n",
    "    im = cv2.imread(data_dir + 'img_resized/' + filename) # read image as numpy array\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB) # convert to RGB\n",
    "    if key not in data_dict: missing_keys.append(key) # photos > posts\n",
    "    else: data_dict[key].img = im\n",
    "\n",
    "pickle.dump(data_dict, open(pickle_dir + 'complete_dataset.pkl', 'rb'))\n",
    "print('Number of images with no corresponding tweet:', len(missing_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
